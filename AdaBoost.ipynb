{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score,train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=pd.read_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>travel_time</th>\n",
       "      <th>date_of_year</th>\n",
       "      <th>year</th>\n",
       "      <th>mo</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day_binned</th>\n",
       "      <th>day_hour</th>\n",
       "      <th>time_binned</th>\n",
       "      <th>day_number</th>\n",
       "      <th>day_cosine</th>\n",
       "      <th>day_sine</th>\n",
       "      <th>time_cosine</th>\n",
       "      <th>time_sine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-18 03:25:25</td>\n",
       "      <td>40.731525</td>\n",
       "      <td>-73.988670</td>\n",
       "      <td>40.760036</td>\n",
       "      <td>-73.984856</td>\n",
       "      <td>626</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.532032</td>\n",
       "      <td>0.846724</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-25 17:09:52</td>\n",
       "      <td>40.713608</td>\n",
       "      <td>-74.013718</td>\n",
       "      <td>40.765598</td>\n",
       "      <td>-73.980713</td>\n",
       "      <td>1192</td>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.244048</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>0.999301</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-05 00:17:41</td>\n",
       "      <td>40.773960</td>\n",
       "      <td>-73.874435</td>\n",
       "      <td>40.766693</td>\n",
       "      <td>-73.955414</td>\n",
       "      <td>842</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01 07:44:33</td>\n",
       "      <td>40.749718</td>\n",
       "      <td>-73.991570</td>\n",
       "      <td>40.768169</td>\n",
       "      <td>-73.912483</td>\n",
       "      <td>1054</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.755952</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>-0.999301</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-29 14:34:21</td>\n",
       "      <td>40.762730</td>\n",
       "      <td>-73.974174</td>\n",
       "      <td>40.779640</td>\n",
       "      <td>-73.961823</td>\n",
       "      <td>538</td>\n",
       "      <td>2016-05-29</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      pickup_datetime  pickup_latitude  pickup_longitude  \\\n",
       "0           0  2016-01-18 03:25:25        40.731525        -73.988670   \n",
       "1           1  2016-01-25 17:09:52        40.713608        -74.013718   \n",
       "2           2  2016-01-05 00:17:41        40.773960        -73.874435   \n",
       "3           3  2016-01-01 07:44:33        40.749718        -73.991570   \n",
       "4           4  2016-05-29 14:34:21        40.762730        -73.974174   \n",
       "\n",
       "   dropoff_latitude  dropoff_longitude  travel_time date_of_year  year  mo  \\\n",
       "0         40.760036         -73.984856          626   2016-01-18  2016   1   \n",
       "1         40.765598         -73.980713         1192   2016-01-25  2016   1   \n",
       "2         40.766693         -73.955414          842   2016-01-05  2016   1   \n",
       "3         40.768169         -73.912483         1054   2016-01-01  2016   1   \n",
       "4         40.779640         -73.961823          538   2016-05-29  2016   5   \n",
       "\n",
       "   ...  day_of_week  weekday  day_binned  day_hour  time_binned  day_number  \\\n",
       "0  ...          1.0      1.0    0.142857       3.0     0.125000    0.160714   \n",
       "1  ...          1.0      1.0    0.142857      17.0     0.708333    0.244048   \n",
       "2  ...          2.0      1.0    0.285714       0.0     0.000000    0.285714   \n",
       "3  ...          5.0      1.0    0.714286       7.0     0.291667    0.755952   \n",
       "4  ...          0.0      0.0    0.000000      14.0     0.583333    0.083333   \n",
       "\n",
       "   day_cosine  day_sine  time_cosine  time_sine  \n",
       "0    0.532032  0.846724     0.707107   0.707107  \n",
       "1    0.037391  0.999301    -0.258819  -0.965926  \n",
       "2   -0.222521  0.974928     1.000000   0.000000  \n",
       "3    0.037391 -0.999301    -0.258819   0.965926  \n",
       "4    0.866025  0.500000    -0.866025  -0.500000  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'pickup_datetime', 'pickup_latitude', 'pickup_longitude',\n",
       "       'dropoff_latitude', 'dropoff_longitude', 'travel_time', 'date_of_year',\n",
       "       'year', 'mo', 'da', 'temp', 'visib', 'wdsp', 'gust', 'max', 'min',\n",
       "       'prcp', 'sndp', 'fog', 'rain_drizzle', 'snow_ice_pellets', 'hail',\n",
       "       'thunder', 'distance_in_km', 'Pickup Geohash', 'Dropoff Geohash',\n",
       "       'day_of_week', 'weekday', 'day_binned', 'day_hour', 'time_binned',\n",
       "       'day_number', 'day_cosine', 'day_sine', 'time_cosine', 'time_sine'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation before prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           0.009183\n",
       "pickup_latitude     -0.061481\n",
       "pickup_longitude     0.096247\n",
       "dropoff_latitude    -0.127299\n",
       "dropoff_longitude    0.080626\n",
       "travel_time          1.000000\n",
       "year                      NaN\n",
       "mo                   0.062146\n",
       "da                   0.011005\n",
       "temp                 0.057647\n",
       "visib                0.009210\n",
       "wdsp                 0.014894\n",
       "gust                 0.032461\n",
       "max                  0.052568\n",
       "min                  0.056567\n",
       "prcp                -0.010622\n",
       "sndp                 0.026657\n",
       "fog                 -0.017600\n",
       "rain_drizzle        -0.002133\n",
       "snow_ice_pellets    -0.031429\n",
       "hail                      NaN\n",
       "thunder                   NaN\n",
       "distance_in_km       0.734535\n",
       "day_of_week          0.028139\n",
       "weekday              0.072720\n",
       "day_binned           0.028139\n",
       "day_hour             0.030524\n",
       "time_binned          0.030524\n",
       "day_number           0.031871\n",
       "day_cosine          -0.069807\n",
       "day_sine            -0.038148\n",
       "time_cosine         -0.070464\n",
       "time_sine           -0.040119\n",
       "Name: travel_time, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.corr()['travel_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create variables for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list=['pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude','distance_in_km','temp','wdsp','prcp','sndp','day_number','day_cosine','day_sine','time_cosine','time_sine']\n",
    "y=features['travel_time']\n",
    "X=features[features_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Test split using KFold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=3, random_state=None, shuffle=False)\n",
      "TRAIN: [ 947508  947509  947510 ... 2842521 2842522 2842523] TEST: [     0      1      2 ... 947505 947506 947507]\n",
      "TRAIN: [      0       1       2 ... 2842521 2842522 2842523] TEST: [ 947508  947509  947510 ... 1895013 1895014 1895015]\n",
      "TRAIN: [      0       1       2 ... 1895013 1895014 1895015] TEST: [1895016 1895017 1895018 ... 2842521 2842522 2842523]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "kf.get_n_splits(X)\n",
    "print(kf)  \n",
    "KFold(n_splits=3, random_state=2, shuffle=False)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain=X_train[:100000]\n",
    "ytrain=y_train[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest=X_test[:25000]\n",
    "ytest=y_test[:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain=scale(Xtrain)\n",
    "Xtest=scale(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for prediction and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_score(clf,Xtrain,ytrain,Xtest,ytest):\n",
    "    clf.fit(Xtrain,ytrain)\n",
    "    y_pred_train=clf.predict(Xtrain)\n",
    "    y_pred_test=clf.predict(Xtest)\n",
    "    print('r2 score train :',r2_score(ytrain,y_pred_train))\n",
    "    print('r2 score test :',r2_score(ytest,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tune the regressor hyperparameters using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 9 candidates, totalling 36 fits\n",
      "[CV] learning_rate=0.001, n_estimators=5 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, n_estimators=5, score=0.5541155954060089, total=   1.4s\n",
      "[CV] learning_rate=0.001, n_estimators=5 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, n_estimators=5, score=0.566403539367393, total=   1.3s\n",
      "[CV] learning_rate=0.001, n_estimators=5 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, n_estimators=5, score=0.5602452402237024, total=   1.3s\n",
      "[CV] learning_rate=0.001, n_estimators=5 .............................\n",
      "[CV]  learning_rate=0.001, n_estimators=5, score=0.5558017546084937, total=   1.3s\n",
      "[CV] learning_rate=0.001, n_estimators=20 ............................\n",
      "[CV]  learning_rate=0.001, n_estimators=20, score=0.5553715468360592, total=   4.9s\n",
      "[CV] learning_rate=0.001, n_estimators=20 ............................\n",
      "[CV]  learning_rate=0.001, n_estimators=20, score=0.566271386947382, total=   5.0s\n",
      "[CV] learning_rate=0.001, n_estimators=20 ............................\n",
      "[CV]  learning_rate=0.001, n_estimators=20, score=0.5623802144792729, total=   4.8s\n",
      "[CV] learning_rate=0.001, n_estimators=20 ............................\n",
      "[CV]  learning_rate=0.001, n_estimators=20, score=0.5554103369827741, total=   4.9s\n",
      "[CV] learning_rate=0.001, n_estimators=50 ............................\n",
      "[CV]  learning_rate=0.001, n_estimators=50, score=0.5552116078175872, total=  12.4s\n",
      "[CV] learning_rate=0.001, n_estimators=50 ............................\n",
      "[CV]  learning_rate=0.001, n_estimators=50, score=0.5680497558448189, total=  12.5s\n",
      "[CV] learning_rate=0.001, n_estimators=50 ............................\n",
      "[CV]  learning_rate=0.001, n_estimators=50, score=0.561849643367407, total=  12.5s\n",
      "[CV] learning_rate=0.001, n_estimators=50 ............................\n",
      "[CV]  learning_rate=0.001, n_estimators=50, score=0.5556801342970046, total=  12.5s\n",
      "[CV] learning_rate=0.01, n_estimators=5 ..............................\n",
      "[CV]  learning_rate=0.01, n_estimators=5, score=0.5542075915102493, total=   1.3s\n",
      "[CV] learning_rate=0.01, n_estimators=5 ..............................\n",
      "[CV]  learning_rate=0.01, n_estimators=5, score=0.5655959363395349, total=   1.3s\n",
      "[CV] learning_rate=0.01, n_estimators=5 ..............................\n",
      "[CV]  learning_rate=0.01, n_estimators=5, score=0.5597977719243076, total=   1.2s\n",
      "[CV] learning_rate=0.01, n_estimators=5 ..............................\n",
      "[CV]  learning_rate=0.01, n_estimators=5, score=0.5578228164395833, total=   1.3s\n",
      "[CV] learning_rate=0.01, n_estimators=20 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=20, score=0.5550723003306803, total=   4.9s\n",
      "[CV] learning_rate=0.01, n_estimators=20 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=20, score=0.5686638611162282, total=   5.0s\n",
      "[CV] learning_rate=0.01, n_estimators=20 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=20, score=0.560197297474413, total=   5.0s\n",
      "[CV] learning_rate=0.01, n_estimators=20 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=20, score=0.5565692370451039, total=   5.0s\n",
      "[CV] learning_rate=0.01, n_estimators=50 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=50, score=0.558149576688054, total=  12.5s\n",
      "[CV] learning_rate=0.01, n_estimators=50 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=50, score=0.5710517965380439, total=  12.2s\n",
      "[CV] learning_rate=0.01, n_estimators=50 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=50, score=0.5640729423547289, total=  12.4s\n",
      "[CV] learning_rate=0.01, n_estimators=50 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=50, score=0.5580387573266105, total=  12.8s\n",
      "[CV] learning_rate=0.1, n_estimators=5 ...............................\n",
      "[CV]  learning_rate=0.1, n_estimators=5, score=0.557712339682245, total=   1.3s\n",
      "[CV] learning_rate=0.1, n_estimators=5 ...............................\n",
      "[CV]  learning_rate=0.1, n_estimators=5, score=0.5673170832519774, total=   1.3s\n",
      "[CV] learning_rate=0.1, n_estimators=5 ...............................\n",
      "[CV]  learning_rate=0.1, n_estimators=5, score=0.5602413966283373, total=   1.3s\n",
      "[CV] learning_rate=0.1, n_estimators=5 ...............................\n",
      "[CV]  learning_rate=0.1, n_estimators=5, score=0.5549663652804129, total=   1.3s\n",
      "[CV] learning_rate=0.1, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.1, n_estimators=20, score=0.5616304772487661, total=   5.3s\n",
      "[CV] learning_rate=0.1, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.1, n_estimators=20, score=0.5772122439580396, total=   5.2s\n",
      "[CV] learning_rate=0.1, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.1, n_estimators=20, score=0.5742633426059758, total=   5.0s\n",
      "[CV] learning_rate=0.1, n_estimators=20 ..............................\n",
      "[CV]  learning_rate=0.1, n_estimators=20, score=0.5696227635902451, total=   7.7s\n",
      "[CV] learning_rate=0.1, n_estimators=50 ..............................\n",
      "[CV]  learning_rate=0.1, n_estimators=50, score=0.5434626075944783, total=  18.7s\n",
      "[CV] learning_rate=0.1, n_estimators=50 ..............................\n",
      "[CV]  learning_rate=0.1, n_estimators=50, score=0.55714963144776, total=  18.1s\n",
      "[CV] learning_rate=0.1, n_estimators=50 ..............................\n",
      "[CV]  learning_rate=0.1, n_estimators=50, score=0.5479863688834214, total=  18.7s\n",
      "[CV] learning_rate=0.1, n_estimators=50 ..............................\n",
      "[CV]  learning_rate=0.1, n_estimators=50, score=0.5348139228698436, total=  18.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'learning_rate': 0.1, 'n_estimators': 20}\n",
      "Best score is 0.5706822068507567\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\"learning_rate\": [0.001,0.01,0.1],\n",
    "              \"n_estimators\": [5,20,50]\n",
    "              }\n",
    "clf=AdaBoostRegressor()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "clf_cv = GridSearchCV(clf,param_dist, cv= 4 ,verbose=3)\n",
    "\n",
    "# Fit it to the data\n",
    "clf_cv.fit(Xtrain,ytrain)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(clf_cv.best_params_))\n",
    "print(\"Best score is {}\".format(clf_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=clf_cv.predict(Xtrain)\n",
    "y_pred_test=clf_cv.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5669709644672545"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(ytrain,y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49369642404872205"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(ytest,y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New training and feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=AdaBoostRegressor(learning_rate=0.1,n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='linear',\n",
       "         n_estimators=20, random_state=None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickup_latitude 0.0\n",
      "pickup_longitude 0.0025698966723955324\n",
      "dropoff_latitude 0.001026338814776694\n",
      "dropoff_longitude 0.0\n",
      "distance_in_km 0.9457300203977873\n",
      "temp 0.0\n",
      "wdsp 0.0\n",
      "prcp 0.0\n",
      "sndp 0.026958012887041926\n",
      "day_number 0.0\n",
      "day_cosine 0.0\n",
      "day_sine 0.0\n",
      "time_cosine 0.02371573122799847\n",
      "time_sine 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(clf.feature_importances_)):\n",
    "    print(features_list[i],clf.feature_importances_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_dataset(X):\n",
    "    clf=PCA(n_components=2)\n",
    "    clf.fit(X)\n",
    "    pca_x=clf.transform(X)\n",
    "    pca_data=np.concatenate((X,pca_x),axis=1)\n",
    "    return pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train=pca_dataset(Xtrain)\n",
    "pca_test=pca_dataset(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train : 0.5708410408290184\n",
      "r2 score test: 0.49719602370397775\n"
     ]
    }
   ],
   "source": [
    "clf=AdaBoostRegressor(learning_rate=0.1,n_estimators=20)\n",
    "pred_score(clf,pca_train,ytrain,pca_test,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see small improvement with the PCA feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train : 0.6834434135926122\n",
      "r2 score test: 0.523432577993215\n"
     ]
    }
   ],
   "source": [
    "xgb=XGBRegressor()\n",
    "pred_score(xgb,Xtrain,ytrain,Xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train : 0.684249942325111\n",
      "r2 score test: 0.489041630581849\n"
     ]
    }
   ],
   "source": [
    "# see how pca impact default XGBoost prediction\n",
    "xgb=XGBRegressor()\n",
    "pred_score(xgb,pca_train,ytrain,pca_test,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see improvement on performances compared to AdaBoost but performances are not convincing yet. We need parameter tuning to improve results here which can be found in the XGBoost notebook.\n",
    "We see that PCA feature does not improve performances on the test set so we might not consider it in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train : 0.6837703241541504\n",
      "r2 score test: 0.5201954688294059\n"
     ]
    }
   ],
   "source": [
    "clf=GradientBoostingRegressor()\n",
    "pred_score(clf,Xtrain,ytrain,Xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train : 0.6848157129321398\n",
      "r2 score test: 0.4810471605600539\n"
     ]
    }
   ],
   "source": [
    "clf=GradientBoostingRegressor()\n",
    "pred_score(clf,pca_train,ytrain,pca_test,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't see significant improvement between gradient boosting and xgboost. As xgboost is supposed to be more efficient in term of computational speed we will stick with that model. PCA feature does not improve performances either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
