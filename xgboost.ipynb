{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=pd.read_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>travel_time</th>\n",
       "      <th>date_of_year</th>\n",
       "      <th>year</th>\n",
       "      <th>mo</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day_binned</th>\n",
       "      <th>day_hour</th>\n",
       "      <th>time_binned</th>\n",
       "      <th>day_number</th>\n",
       "      <th>day_cosine</th>\n",
       "      <th>day_sine</th>\n",
       "      <th>time_cosine</th>\n",
       "      <th>time_sine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-18 03:25:25</td>\n",
       "      <td>40.731525</td>\n",
       "      <td>-73.988670</td>\n",
       "      <td>40.760036</td>\n",
       "      <td>-73.984856</td>\n",
       "      <td>626</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.532032</td>\n",
       "      <td>0.846724</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-25 17:09:52</td>\n",
       "      <td>40.713608</td>\n",
       "      <td>-74.013718</td>\n",
       "      <td>40.765598</td>\n",
       "      <td>-73.980713</td>\n",
       "      <td>1192</td>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.244048</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>0.999301</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-05 00:17:41</td>\n",
       "      <td>40.773960</td>\n",
       "      <td>-73.874435</td>\n",
       "      <td>40.766693</td>\n",
       "      <td>-73.955414</td>\n",
       "      <td>842</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01 07:44:33</td>\n",
       "      <td>40.749718</td>\n",
       "      <td>-73.991570</td>\n",
       "      <td>40.768169</td>\n",
       "      <td>-73.912483</td>\n",
       "      <td>1054</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.755952</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>-0.999301</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-29 14:34:21</td>\n",
       "      <td>40.762730</td>\n",
       "      <td>-73.974174</td>\n",
       "      <td>40.779640</td>\n",
       "      <td>-73.961823</td>\n",
       "      <td>538</td>\n",
       "      <td>2016-05-29</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      pickup_datetime  pickup_latitude  pickup_longitude  \\\n",
       "0           0  2016-01-18 03:25:25        40.731525        -73.988670   \n",
       "1           1  2016-01-25 17:09:52        40.713608        -74.013718   \n",
       "2           2  2016-01-05 00:17:41        40.773960        -73.874435   \n",
       "3           3  2016-01-01 07:44:33        40.749718        -73.991570   \n",
       "4           4  2016-05-29 14:34:21        40.762730        -73.974174   \n",
       "\n",
       "   dropoff_latitude  dropoff_longitude  travel_time date_of_year  year  mo  \\\n",
       "0         40.760036         -73.984856          626   2016-01-18  2016   1   \n",
       "1         40.765598         -73.980713         1192   2016-01-25  2016   1   \n",
       "2         40.766693         -73.955414          842   2016-01-05  2016   1   \n",
       "3         40.768169         -73.912483         1054   2016-01-01  2016   1   \n",
       "4         40.779640         -73.961823          538   2016-05-29  2016   5   \n",
       "\n",
       "   ...  day_of_week  weekday  day_binned  day_hour  time_binned  day_number  \\\n",
       "0  ...          1.0      1.0    0.142857       3.0     0.125000    0.160714   \n",
       "1  ...          1.0      1.0    0.142857      17.0     0.708333    0.244048   \n",
       "2  ...          2.0      1.0    0.285714       0.0     0.000000    0.285714   \n",
       "3  ...          5.0      1.0    0.714286       7.0     0.291667    0.755952   \n",
       "4  ...          0.0      0.0    0.000000      14.0     0.583333    0.083333   \n",
       "\n",
       "   day_cosine  day_sine  time_cosine  time_sine  \n",
       "0    0.532032  0.846724     0.707107   0.707107  \n",
       "1    0.037391  0.999301    -0.258819  -0.965926  \n",
       "2   -0.222521  0.974928     1.000000   0.000000  \n",
       "3    0.037391 -0.999301    -0.258819   0.965926  \n",
       "4    0.866025  0.500000    -0.866025  -0.500000  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list=['pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude','weekday','distance_in_km','temp','wdsp','prcp','sndp','day_number','day_cosine','day_sine','time_cosine','time_sine']\n",
    "y=features['travel_time']\n",
    "X=features[features_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=2, random_state=None, shuffle=False)\n",
      "TRAIN: [1421262 1421263 1421264 ... 2842521 2842522 2842523] TEST: [      0       1       2 ... 1421259 1421260 1421261]\n",
      "TRAIN: [      0       1       2 ... 1421259 1421260 1421261] TEST: [1421262 1421263 1421264 ... 2842521 2842522 2842523]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=2)\n",
    "kf.get_n_splits(X)\n",
    "print(kf)  \n",
    "KFold(n_splits=2, random_state=2, shuffle=False)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Xtrain, Xtest = X.loc[train_index], X.loc[test_index]\n",
    "    ytrain, ytest = y.loc[train_index], y.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain=Xtrain[:100000]\n",
    "ytrain=ytrain[:100000]\n",
    "Xtest=Xtest[:25000]\n",
    "ytest=ytest[:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain=scale(Xtrain)\n",
    "Xtest=scale(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, features,labels,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgboost.DMatrix(features, label=labels)\n",
    "        cvresult = xgboost.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='rmse', early_stopping_rounds=early_stopping_rounds)\n",
    "        print(cvresult)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(features, labels,eval_metric='rmse')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(features)\n",
    "        \n",
    "    print(\"R2 score :\", r2_score(ytrain,dtrain_predictions))\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the optimum number of estimator using xgboost cv function with other parameters fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
      "0         796.252051        0.552670      796.310437       2.365287\n",
      "1         731.079749        3.688860      731.315784       4.794822\n",
      "2         672.691785        3.405338      673.027344       3.886870\n",
      "3         622.404517        6.186040      622.928235       6.088620\n",
      "4         576.411230        5.094663      577.112842       4.147696\n",
      "5         535.114282        4.387537      535.899890       3.541034\n",
      "6         501.072876        4.963129      501.985199       3.808671\n",
      "7         469.872302        3.621091      470.811658       3.362934\n",
      "8         443.768182        4.610129      444.843280       4.205229\n",
      "9         420.319360        3.503945      421.471161       4.026793\n",
      "10        399.903473        3.238527      401.236108       3.931440\n",
      "11        382.369885        2.498136      383.842096       3.744252\n",
      "12        367.416754        2.533653      369.002624       3.878482\n",
      "13        354.412762        1.821093      356.095178       2.898391\n",
      "14        343.130170        1.492654      344.944208       2.751153\n",
      "15        333.801471        1.832165      335.743713       2.726267\n",
      "16        326.441657        2.446466      328.543573       2.799287\n",
      "17        319.397510        2.044082      321.535907       2.305549\n",
      "18        313.416363        1.853615      315.658325       1.853889\n",
      "19        308.697321        2.092501      311.013141       2.277461\n",
      "20        304.398468        2.242516      306.792102       2.471898\n",
      "21        300.577380        1.881849      303.080481       2.149254\n",
      "22        297.220441        1.574892      299.814716       2.215397\n",
      "23        294.537951        1.307661      297.240241       2.302115\n",
      "24        292.092444        1.066184      294.852673       2.272808\n",
      "25        290.077966        1.049802      292.920215       2.161193\n",
      "26        288.068756        0.840216      290.988281       2.185450\n",
      "27        286.213001        0.777328      289.190430       2.103670\n",
      "28        284.671875        0.730686      287.746136       2.155825\n",
      "29        283.327142        0.672736      286.472974       2.166911\n",
      "..               ...             ...             ...            ...\n",
      "970       192.818494        0.495722      240.056818       2.094043\n",
      "971       192.777490        0.490260      240.052573       2.093112\n",
      "972       192.721213        0.499796      240.055048       2.087477\n",
      "973       192.679007        0.506510      240.055423       2.089086\n",
      "974       192.641153        0.517952      240.057361       2.087260\n",
      "975       192.599234        0.507539      240.048053       2.082800\n",
      "976       192.573816        0.507360      240.046735       2.089061\n",
      "977       192.548438        0.509160      240.048752       2.083556\n",
      "978       192.511404        0.513700      240.045706       2.079175\n",
      "979       192.483270        0.517123      240.041510       2.075047\n",
      "980       192.444705        0.499748      240.037311       2.079841\n",
      "981       192.419555        0.502036      240.034903       2.078692\n",
      "982       192.383859        0.495478      240.032297       2.076015\n",
      "983       192.349878        0.500535      240.025842       2.074602\n",
      "984       192.307541        0.499310      240.021448       2.072869\n",
      "985       192.287650        0.497065      240.022669       2.071504\n",
      "986       192.251922        0.501293      240.018591       2.072350\n",
      "987       192.204352        0.497612      240.003986       2.084144\n",
      "988       192.164908        0.492626      239.995712       2.087113\n",
      "989       192.122525        0.501429      239.985382       2.086606\n",
      "990       192.093299        0.499977      239.988983       2.085367\n",
      "991       192.043689        0.496495      239.983255       2.088389\n",
      "992       192.018756        0.495327      239.984198       2.092344\n",
      "993       191.987335        0.499836      239.989886       2.086182\n",
      "994       191.948822        0.505886      239.987991       2.087909\n",
      "995       191.919476        0.491204      239.995026       2.099664\n",
      "996       191.882440        0.486927      239.988303       2.094261\n",
      "997       191.845395        0.489388      239.975272       2.087712\n",
      "998       191.819333        0.484477      239.975351       2.080749\n",
      "999       191.784833        0.488949      239.969385       2.084213\n",
      "\n",
      "[1000 rows x 4 columns]\n",
      "\n",
      "Model Report\n",
      "R2 score : 0.8396648748362072\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBRegressor(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'reg:linear',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1.get_params()['n_estimators']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start tuning with Randomized GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB parameters : \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method XGBModel.get_params of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb=XGBRegressor()\n",
    "print('XGB parameters : \\n')\n",
    "xgb.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth=range(3,16,3)\n",
    "min_child_weight=range(3,16,3)\n",
    "gamma=[i/10.0 for i in range(0,5)]\n",
    "subsample=[i/10.0 for i in range(0,10)]\n",
    "colsample_by_tree=[i/10.0 for i in range(6,10)]\n",
    "reg_lambda=[0.1,0.5,1,10]\n",
    "random_grid={'max_depth':max_depth,'min_child_weight':min_child_weight,'gamma':gamma,'subsample':subsample,\n",
    "            'colsample_by_tree':colsample_by_tree,'reg_lambda':reg_lambda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 36.0min finished\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'max_depth': range(3, 16, 3), 'min_child_weight': range(3, 16, 3), 'gamma': [0.0, 0.1, 0.2, 0.3, 0.4], 'subsample': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_by_tree': [0.6, 0.7, 0.8, 0.9], 'reg_lambda': [0.1, 0.5, 1, 10]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor()\n",
    "random_search = RandomizedSearchCV(estimator = xgb, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "random_search.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.7,\n",
       " 'reg_lambda': 10,\n",
       " 'min_child_weight': 3,\n",
       " 'max_depth': 15,\n",
       " 'gamma': 0.1,\n",
       " 'colsample_by_tree': 0.8}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train : 0.6834434135926122\n",
      "r2 score test : 0.5927955351614118\n"
     ]
    }
   ],
   "source": [
    "xgb=XGBRegressor()\n",
    "pred_score(xgb,Xtrain,ytrain,Xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train : 0.9160875990871591\n",
      "r2 score test : 0.5793630775697541\n"
     ]
    }
   ],
   "source": [
    "xgb=XGBRegressor(subsample=0.7,reg_lambda=10,min_child_weight=3,max_depth=15,gamma=0.1,colsample_by_tree=0.8)\n",
    "pred_score(xgb,Xtrain,ytrain,Xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our model overfits, let's play on parameters that influence that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train : 0.9110656582217659\n",
      "r2 score test : 0.5910787784866613\n"
     ]
    }
   ],
   "source": [
    "xgb=XGBRegressor(subsample=0.7,reg_lambda=10,min_child_weight=5,max_depth=15,gamma=0.1,colsample_by_tree=0.8)\n",
    "pred_score(xgb,Xtrain,ytrain,Xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train : 0.8894331918809966\n",
      "r2 score test : 0.593201968981093\n"
     ]
    }
   ],
   "source": [
    "xgb=XGBRegressor(subsample=0.5,reg_lambda=10,min_child_weight=5,max_depth=15,gamma=0.1,colsample_by_tree=0.8)\n",
    "pred_score(xgb,Xtrain,ytrain,Xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train : 0.8932465983293977\n",
      "r2 score test : 0.597582334551987\n"
     ]
    }
   ],
   "source": [
    "xgb=XGBRegressor(subsample=0.6,reg_lambda=10,min_child_weight=7,max_depth=15,gamma=0.1,colsample_by_tree=0.8)\n",
    "pred_score(xgb,Xtrain,ytrain,Xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fine tune the parameters better in order to try reduce overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function for parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(Xtrain,ytrain,param_dict,learning_rate,n_estimators,max_depth,min_child_weight,gamma,subsample,colsample_bytree,reg_lambda):\n",
    "    clf=GridSearchCV(estimator=XGBRegressor(learning_rate=learning_rate,n_estimators=n_estimators,max_depth=max_depth,\n",
    "                                           min_child_weight=min_child_weight,gamma=gamma,subsample=subsample,\n",
    "                                            colsample_bytree=colsample_bytree,objective='reg:linear',reg_lambda=10,\n",
    "                                            n_thread=4,scale_pos_weight=1,seed=27),\n",
    "                    param_grid=param_dict,scoring='r2',n_jobs=4,iid=False,cv=5,verbose=3)\n",
    "    clf.fit(Xtrain,ytrain)\n",
    "    print(clf.best_params_)\n",
    "    print(clf.best_score_)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for prediction and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_score(clf,Xtrain,ytrain,Xtest,ytest):\n",
    "    clf.fit(Xtrain,ytrain)\n",
    "    y_pred_train=clf.predict(Xtrain)\n",
    "    y_pred_test=clf.predict(Xtest)\n",
    "    print('r2 score train :',r2_score(ytrain,y_pred_train))\n",
    "    print('r2 score test :',r2_score(ytest,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using this set number of estimators find the best max_depth and min_child_weight parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed: 22.7min\n",
      "[Parallel(n_jobs=4)]: Done 125 out of 125 | elapsed: 210.9min finished\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'min_child_weight': 11}\n",
      "0.7736486810227513\n"
     ]
    }
   ],
   "source": [
    "param_dict = {\n",
    " 'max_depth':range(10,20,2),\n",
    " 'min_child_weight':range(5,15,2)\n",
    "}\n",
    "clf=tune(Xtrain,ytrain,param_dict,0.1,500,5,1,0.1,0.6,0.8,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train : 0.827754658075694\n",
      "r2 score test : 0.6056992584085336\n"
     ]
    }
   ],
   "source": [
    "xgb=xgb=XGBRegressor(subsample=0.6,reg_lambda=10,min_child_weight=11,max_depth=10,gamma=0.1,colsample_by_tree=0.8)\n",
    "pred_score(xgb,Xtrain,ytrain,Xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to reduce overfitting a little so we'll keep optimizing on these parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to find the optimum looking for values one below and one above the optimum found becasue we took an interval of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed: 49.3min\n",
      "[Parallel(n_jobs=4)]: Done  45 out of  45 | elapsed: 88.8min finished\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'min_child_weight': 11}\n",
      "0.7736486810227513\n"
     ]
    }
   ],
   "source": [
    "param_dict = {\n",
    " 'max_depth':[9,10,11],\n",
    " 'min_child_weight':[10,11,12]\n",
    "}\n",
    "clf=tune(Xtrain,ytrain,param_dict,0.1,500,5,1,0,0.6,0.8,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train : 0.827754658075694\n",
      "r2 score test : 0.6056992584085336\n"
     ]
    }
   ],
   "source": [
    "xgb=xgb=XGBRegressor(subsample=0.6,reg_lambda=10,min_child_weight=11,max_depth=10,gamma=0.1,colsample_by_tree=0.8)\n",
    "pred_score(xgb,Xtrain,ytrain,Xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed: 23.0min finished\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.3}\n",
      "0.7744359219929466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=11, missing=None, n_estimators=500, n_jobs=1,\n",
       "       n_thread=4, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=10, scale_pos_weight=1, seed=27,\n",
       "       silent=True, subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=4,\n",
       "       param_grid={'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='r2', verbose=3)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "tune(Xtrain,ytrain,param_dict,0.1,500,10,11,0,0.8,0.8,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train : 0.827754658075694\n",
      "r2 score test : 0.6056992584085336\n"
     ]
    }
   ],
   "source": [
    "xgb=xgb=XGBRegressor(subsample=0.6,reg_lambda=10,min_child_weight=11,max_depth=10,gamma=0.3,colsample_by_tree=0.8)\n",
    "pred_score(xgb,Xtrain,ytrain,Xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
      "0         794.718835        0.571562      795.198621       2.315094\n",
      "1         727.367517        2.672637      728.490417       3.934778\n",
      "2         666.837476        2.562578      668.541626       3.195307\n",
      "3         614.179578        4.669309      616.683691       4.569217\n",
      "4         566.138818        3.839286      569.329175       2.953460\n",
      "5         522.868689        3.487143      526.994592       2.684311\n",
      "6         486.564001        4.348575      491.563312       3.508267\n",
      "7         453.266766        3.337970      459.225934       3.155759\n",
      "8         424.744781        4.041599      431.790894       3.943550\n",
      "9         399.191284        3.028875      407.413245       3.994341\n",
      "10        376.406342        2.800383      385.756067       3.709521\n",
      "11        356.627545        2.298003      367.358795       3.661953\n",
      "12        339.512903        2.555952      351.512183       3.595590\n",
      "13        324.396582        1.926906      337.582312       2.818928\n",
      "14        311.101794        1.678654      325.519666       2.699281\n",
      "15        299.820422        1.827116      315.594104       2.555693\n",
      "16        290.403406        2.486512      307.371692       2.462732\n",
      "17        281.641480        2.295942      299.781293       2.097854\n",
      "18        274.124811        2.311324      293.434534       1.740486\n",
      "19        267.890735        2.491761      288.318402       2.081071\n",
      "20        262.063666        2.737867      283.565100       2.378484\n",
      "21        256.915237        2.618423      279.487824       2.202858\n",
      "22        252.464688        2.368736      276.097504       2.350835\n",
      "23        248.981006        2.089771      273.500030       2.282097\n",
      "24        245.330676        1.578790      270.783935       2.301898\n",
      "25        242.549054        1.637288      268.817291       2.147813\n",
      "26        239.611896        1.333022      266.826422       2.232614\n",
      "27        236.817599        1.309794      264.896551       2.149717\n",
      "28        234.253790        1.307767      263.122003       2.207753\n",
      "29        232.340927        1.166899      261.931964       2.148139\n",
      "..               ...             ...             ...            ...\n",
      "461       130.466608        0.356206      236.492551       1.799266\n",
      "462       130.378967        0.356042      236.509738       1.804599\n",
      "463       130.280558        0.345929      236.516971       1.798107\n",
      "464       130.184988        0.355026      236.518631       1.799711\n",
      "465       130.097052        0.380703      236.511600       1.799308\n",
      "466       129.999255        0.388203      236.498593       1.794547\n",
      "467       129.848871        0.378083      236.488843       1.788519\n",
      "468       129.716464        0.397895      236.484119       1.788144\n",
      "469       129.628180        0.360206      236.477307       1.794644\n",
      "470       129.500488        0.378801      236.472574       1.786773\n",
      "471       129.428909        0.403597      236.480218       1.784103\n",
      "472       129.298868        0.453025      236.467649       1.777059\n",
      "473       129.172058        0.413497      236.474948       1.778701\n",
      "474       129.056198        0.442336      236.472165       1.776939\n",
      "475       128.938248        0.422014      236.469611       1.782409\n",
      "476       128.835644        0.436107      236.470904       1.787364\n",
      "477       128.689844        0.452907      236.468555       1.786990\n",
      "478       128.582373        0.424995      236.461460       1.788141\n",
      "479       128.480037        0.431371      236.475211       1.787808\n",
      "480       128.344298        0.454365      236.474908       1.791818\n",
      "481       128.222481        0.478392      236.476208       1.792234\n",
      "482       128.113901        0.490978      236.470853       1.786696\n",
      "483       128.031779        0.507681      236.466171       1.783488\n",
      "484       127.973372        0.522329      236.468277       1.781429\n",
      "485       127.889435        0.533540      236.463883       1.779927\n",
      "486       127.747788        0.482975      236.462305       1.785733\n",
      "487       127.650166        0.487474      236.461325       1.788462\n",
      "488       127.549351        0.484788      236.467313       1.789850\n",
      "489       127.471474        0.492724      236.467251       1.789921\n",
      "490       127.345194        0.510766      236.459500       1.795514\n",
      "\n",
      "[491 rows x 4 columns]\n",
      "R2 score : 0.9253954653741256\n"
     ]
    }
   ],
   "source": [
    "#recalibrate number of estimators given new parameters\n",
    "xgb = XGBRegressor(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=10,\n",
    " min_child_weight=11,\n",
    " gamma=0.3,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'reg:linear',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb, Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.get_params()['n_estimators']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the prediction scores on the training set and test set up to that point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=XGBRegressor( learning_rate =0.1,\n",
    " n_estimators=491,\n",
    " max_depth=10,\n",
    " min_child_weight=11,\n",
    " gamma=0.3,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'reg:linear',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train : 0.9253954653741256\n",
      "r2 score test : 0.6555601289437389\n"
     ]
    }
   ],
   "source": [
    "pred_score(xgb,Xtrain,ytrain,Xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There still is overfitting but we are getting better results on the test set. Let's keep tuning the parameters to improve performances. We will, then, train with optimized parameters on the whole dataset using a GPU to see how the model performs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsample and col_by_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed: 67.7min finished\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8, 'subsample': 0.7}\n",
      "0.7740616462812846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.3, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=11, missing=None, n_estimators=491, n_jobs=1,\n",
       "       n_thread=4, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=10, scale_pos_weight=1, seed=27,\n",
       "       silent=True, subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=4,\n",
       "       param_grid={'subsample': [0.4, 0.5, 0.6, 0.7], 'colsample_bytree': [0.5, 0.6, 0.7, 0.8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='r2', verbose=3)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = {\n",
    " 'subsample':[i/10.0 for i in range(4,8)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(5,9)]\n",
    "}\n",
    "tune(Xtrain,ytrain,param_dict,0.1,491,10,11,0.3,0.8,0.8,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train : 0.9150970001302643\n",
      "r2 score test : 0.6310970741395889\n"
     ]
    }
   ],
   "source": [
    "xgb=xgb=XGBRegressor(n_estimators=491,subsample=0.7,reg_lambda=10,min_child_weight=11,max_depth=10,gamma=0.1,colsample_by_tree=0.8)\n",
    "pred_score(xgb,Xtrain,ytrain,Xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization parameter alpha for L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed: 23.3min finished\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 10}\n",
      "0.7741241838735055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.3, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=11, missing=None, n_estimators=491, n_jobs=1,\n",
       "       n_thread=4, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=10, scale_pos_weight=1, seed=27,\n",
       "       silent=True, subsample=0.7),\n",
       "       fit_params=None, iid=False, n_jobs=4,\n",
       "       param_grid={'reg_alpha': [1e-05, 0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='r2', verbose=3)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 10]\n",
    "}\n",
    "tune(Xtrain,ytrain,param_dict,0.1,491,10,11,0.3,0.7,0.8,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impact of the regularization parameter on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=xgb=XGBRegressor(n_estimators=491,subsample=0.7,\n",
    "                     reg_lambda=10,min_child_weight=11,\n",
    "                     max_depth=10,gamma=0.1,colsample_by_tree=0.8,reg_alpha=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train : 0.9150479060438288\n",
      "r2 score test : 0.6339903953457846\n"
     ]
    }
   ],
   "source": [
    "pred_score(xgb,Xtrain,ytrain,Xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a small improvement on the score on the testing set using alpha regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add more estimators and lower learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
      "0         864.355676        0.547456      864.365588       2.222999\n",
      "1         857.028625        0.586799      857.064465       2.312721\n",
      "2         849.740454        0.635771      849.790784       2.256201\n",
      "3         842.653040        0.844154      842.724585       2.277326\n",
      "4         835.510425        0.913545      835.592065       2.097219\n",
      "5         828.328369        0.900897      828.421765       2.110814\n",
      "6         821.525586        1.030913      821.634631       2.069354\n",
      "7         814.599890        0.869719      814.727808       2.196010\n",
      "8         807.876758        0.998467      808.028870       2.206058\n",
      "9         801.161279        0.789563      801.331360       2.400045\n",
      "10        794.464893        0.795841      794.649536       2.448050\n",
      "11        787.856616        0.740919      788.052307       2.507830\n",
      "12        781.351563        0.805224      781.553235       2.579005\n",
      "13        774.892627        0.799962      775.106165       2.381441\n",
      "14        768.412256        0.778644      768.633838       2.385322\n",
      "15        762.087915        0.907704      762.339050       2.344195\n",
      "16        756.048413        1.157325      756.335132       2.208218\n",
      "17        749.854846        1.185501      750.158228       2.047114\n",
      "18        743.753552        1.271281      744.074573       1.842805\n",
      "19        737.830566        1.446044      738.172168       1.865850\n",
      "20        731.877881        1.607374      732.241663       1.854536\n",
      "21        725.943664        1.651636      726.323926       1.691543\n",
      "22        719.986902        1.628288      720.379187       1.714899\n",
      "23        714.470386        1.372228      714.874536       1.968961\n",
      "24        708.741284        1.292642      709.156885       1.999435\n",
      "25        703.282837        1.485672      703.722986       1.956335\n",
      "26        697.579626        1.472382      698.040576       1.967503\n",
      "27        692.033411        1.316790      692.507459       2.074962\n",
      "28        686.456787        1.301460      686.951551       2.084219\n",
      "29        681.195850        1.221112      681.708545       2.078771\n",
      "..               ...             ...             ...            ...\n",
      "970       201.387817        0.827824      241.121133       2.069442\n",
      "971       201.362250        0.839869      241.110184       2.067731\n",
      "972       201.330756        0.841843      241.099686       2.062113\n",
      "973       201.306103        0.839288      241.091577       2.061786\n",
      "974       201.271847        0.824808      241.076715       2.070592\n",
      "975       201.237155        0.832090      241.062308       2.070240\n",
      "976       201.208688        0.831568      241.054852       2.068512\n",
      "977       201.188602        0.824266      241.051526       2.069158\n",
      "978       201.167053        0.824184      241.044937       2.069843\n",
      "979       201.144901        0.822313      241.034488       2.068264\n",
      "980       201.121494        0.826739      241.027326       2.070332\n",
      "981       201.104529        0.823834      241.023618       2.068166\n",
      "982       201.068619        0.824783      241.009827       2.070199\n",
      "983       201.046710        0.823741      241.001508       2.072811\n",
      "984       201.022812        0.822863      240.993823       2.072561\n",
      "985       200.974954        0.829306      240.974619       2.067588\n",
      "986       200.924353        0.823776      240.944955       2.077531\n",
      "987       200.880151        0.810994      240.928174       2.076955\n",
      "988       200.831534        0.801209      240.907574       2.094370\n",
      "989       200.797443        0.811391      240.895471       2.093522\n",
      "990       200.764026        0.809471      240.880216       2.092737\n",
      "991       200.730905        0.804306      240.870474       2.095004\n",
      "992       200.715186        0.802743      240.867367       2.096041\n",
      "993       200.687466        0.809566      240.856055       2.093440\n",
      "994       200.659741        0.810611      240.844183       2.089355\n",
      "995       200.640317        0.809860      240.837848       2.085068\n",
      "996       200.609717        0.797511      240.827530       2.089402\n",
      "997       200.567236        0.801325      240.808346       2.088717\n",
      "998       200.538275        0.792118      240.798288       2.085085\n",
      "999       200.517056        0.783649      240.792200       2.085212\n",
      "\n",
      "[1000 rows x 4 columns]\n",
      "R2 score : 0.832144442656971\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(\n",
    " learning_rate =0.01,\n",
    " n_estimators=1000,\n",
    " max_depth=10,\n",
    " min_child_weight=11,\n",
    " gamma=0.1,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=10,\n",
    "reg_lambda=10,\n",
    " objective= 'reg:linear',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb,Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train : 0.832144442656971\n",
      "r2 score test : 0.6261618512299532\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(\n",
    " learning_rate =0.01,\n",
    " n_estimators=1000,\n",
    " max_depth=10,\n",
    " min_child_weight=11,\n",
    " gamma=0.1,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=10,\n",
    "reg_lambda=10,\n",
    " objective= 'reg:linear',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "pred_score(xgb,Xtrain,ytrain,Xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is less overfitting but lower scores with more estimators and a lower learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add early stopping to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.1, importance_type='gain',\n",
       "       learning_rate=0.01, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=11, missing=None, n_estimators=1000, n_jobs=1,\n",
       "       nthread=4, objective='reg:linear', random_state=0, reg_alpha=10,\n",
       "       reg_lambda=10, scale_pos_weight=1, seed=27, silent=True,\n",
       "       subsample=0.7)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor(\n",
    " learning_rate =0.01,\n",
    " n_estimators=1000,\n",
    " max_depth=10,\n",
    " min_child_weight=11,\n",
    " gamma=0.1,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=10,\n",
    "reg_lambda=10,\n",
    " objective= 'reg:linear',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "xgb.fit(Xtrain,ytrain,eval_set=[(Xtest, ytest)],early_stopping_rounds=10,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train :  0.8263221682450708\n",
      "r2 score test :  0.6238813843223843\n"
     ]
    }
   ],
   "source": [
    "y_pred_train=xgb.predict(Xtrain)\n",
    "y_pred_test=xgb.predict(Xtest)\n",
    "print('r2 score train : ',r2_score(ytrain,y_pred_train))\n",
    "print('r2 score test : ',r2_score(ytest,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting does not seem to be impacted with 10 early stopping rounds. Let's try to decrease that value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.1, importance_type='gain',\n",
       "       learning_rate=0.01, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=11, missing=None, n_estimators=1000, n_jobs=1,\n",
       "       nthread=4, objective='reg:linear', random_state=0, reg_alpha=10,\n",
       "       reg_lambda=10, scale_pos_weight=1, seed=27, silent=True,\n",
       "       subsample=0.7)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor(\n",
    " learning_rate =0.01,\n",
    " n_estimators=1000,\n",
    " max_depth=10,\n",
    " min_child_weight=11,\n",
    " gamma=0.1,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=10,\n",
    "reg_lambda=10,\n",
    " objective= 'reg:linear',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "xgb.fit(Xtrain,ytrain,eval_set=[(Xtest, ytest)],early_stopping_rounds=5,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train :  0.813907032338403\n",
      "r2 score test :  0.6187003802033468\n"
     ]
    }
   ],
   "source": [
    "y_pred_train=xgb.predict(Xtrain)\n",
    "y_pred_test=xgb.predict(Xtest)\n",
    "print('r2 score train : ',r2_score(ytrain,y_pred_train))\n",
    "print('r2 score test : ',r2_score(ytest,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see if adding more rounds impacts overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.1, importance_type='gain',\n",
       "       learning_rate=0.01, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=11, missing=None, n_estimators=1000, n_jobs=1,\n",
       "       nthread=4, objective='reg:linear', random_state=0, reg_alpha=10,\n",
       "       reg_lambda=10, scale_pos_weight=0, seed=27, silent=True,\n",
       "       subsample=0.7)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor(\n",
    " learning_rate =0.01,\n",
    " n_estimators=1000,\n",
    " max_depth=10,\n",
    " min_child_weight=11,\n",
    " gamma=0.1,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=10,\n",
    "reg_lambda=10,\n",
    " objective= 'reg:linear',\n",
    " nthread=4,\n",
    " scale_pos_weight=0,\n",
    " seed=27)\n",
    "xgb.fit(Xtrain,ytrain,eval_set=[(Xtest, ytest)],early_stopping_rounds=20,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score train :  0.831718276230653\n",
      "r2 score test :  0.6253514726395466\n"
     ]
    }
   ],
   "source": [
    "y_pred_train=xgb.predict(Xtrain)\n",
    "y_pred_test=xgb.predict(Xtest)\n",
    "print('r2 score train : ',r2_score(ytrain,y_pred_train))\n",
    "print('r2 score test : ',r2_score(ytest,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the impact of PCA feature given the optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_dataset(X):\n",
    "    clf=PCA(n_components=2)\n",
    "    clf.fit(X)\n",
    "    pca_x=clf.transform(X)\n",
    "    pca_data=np.concatenate((X,pca_x),axis=1)\n",
    "    return pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train=pca_dataset(Xtrain)\n",
    "pca_test=pca_dataset(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.1, importance_type='gain',\n",
       "       learning_rate=0.01, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=11, missing=None, n_estimators=1000, n_jobs=1,\n",
       "       nthread=4, objective='reg:linear', random_state=0, reg_alpha=10,\n",
       "       reg_lambda=10, scale_pos_weight=1, seed=27, silent=True,\n",
       "       subsample=0.7)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor(\n",
    " learning_rate =0.01,\n",
    " n_estimators=1000,\n",
    " max_depth=10,\n",
    " min_child_weight=11,\n",
    " gamma=0.1,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=10,\n",
    "reg_lambda=10,\n",
    " objective= 'reg:linear',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "xgb.fit(pca_train,ytrain,eval_set=[(pca_test, ytest)],early_stopping_rounds=20,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score train with PCA : 0.8220288700143952\n",
      "Score test with PCA : 0.507098944063589\n"
     ]
    }
   ],
   "source": [
    "y_pred_train=xgb.predict(pca_train)\n",
    "y_pred_test=xgb.predict(pca_test)\n",
    "print('Score train with PCA :',r2_score(ytrain,y_pred_train))\n",
    "print('Score test with PCA :',r2_score(ytest,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't use the PCA feature as it decreases our performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on 1000000 datapoints using the optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list=['pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude','weekday','distance_in_km','temp','wdsp','prcp','sndp','day_number','day_cosine','day_sine','time_cosine','time_sine']\n",
    "y=features['travel_time']\n",
    "X=features[features_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=3, random_state=None, shuffle=False)\n",
      "TRAIN: [ 947508  947509  947510 ... 2842521 2842522 2842523] TEST: [     0      1      2 ... 947505 947506 947507]\n",
      "TRAIN: [      0       1       2 ... 2842521 2842522 2842523] TEST: [ 947508  947509  947510 ... 1895013 1895014 1895015]\n",
      "TRAIN: [      0       1       2 ... 1895013 1895014 1895015] TEST: [1895016 1895017 1895018 ... 2842521 2842522 2842523]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "kf.get_n_splits(X)\n",
    "print(kf)  \n",
    "KFold(n_splits=3, random_state=2, shuffle=False)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Xtrain, Xtest = X.loc[train_index], X.loc[test_index]\n",
    "    ytrain, ytest = y.loc[train_index], y.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1895016, 15)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(947508, 15)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain=Xtrain[:1000000]\n",
    "ytrain=ytrain[:1000000]\n",
    "Xtest=Xtest[:250000]\n",
    "ytest=ytest[:250000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "Xtrain=scale(Xtrain)\n",
    "ytrain=scale(ytrain)\n",
    "Xtest=scale(Xtest)\n",
    "ytest=scale(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb= XGBRegressor(\n",
    " learning_rate =0.01,\n",
    " n_estimators=1000,\n",
    " max_depth=10,\n",
    " min_child_weight=11,\n",
    " gamma=0.1,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=10,\n",
    "reg_lambda=10,\n",
    " objective= 'reg:linear',\n",
    " nthread=4,\n",
    " scale_pos_weight=0,\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:1.10989\n",
      "[1]\tvalidation_0-rmse:1.10173\n",
      "[2]\tvalidation_0-rmse:1.09368\n",
      "[3]\tvalidation_0-rmse:1.08569\n",
      "[4]\tvalidation_0-rmse:1.07792\n",
      "[5]\tvalidation_0-rmse:1.07012\n",
      "[6]\tvalidation_0-rmse:1.06243\n",
      "[7]\tvalidation_0-rmse:1.05483\n",
      "[8]\tvalidation_0-rmse:1.04978\n",
      "[9]\tvalidation_0-rmse:1.04236\n",
      "[10]\tvalidation_0-rmse:1.03663\n",
      "[11]\tvalidation_0-rmse:1.02936\n",
      "[12]\tvalidation_0-rmse:1.02257\n",
      "[13]\tvalidation_0-rmse:1.01794\n",
      "[14]\tvalidation_0-rmse:1.01096\n",
      "[15]\tvalidation_0-rmse:1.00401\n",
      "[16]\tvalidation_0-rmse:0.997443\n",
      "[17]\tvalidation_0-rmse:0.990728\n",
      "[18]\tvalidation_0-rmse:0.985742\n",
      "[19]\tvalidation_0-rmse:0.981196\n",
      "[20]\tvalidation_0-rmse:0.976666\n",
      "[21]\tvalidation_0-rmse:0.970166\n",
      "[22]\tvalidation_0-rmse:0.963722\n",
      "[23]\tvalidation_0-rmse:0.95776\n",
      "[24]\tvalidation_0-rmse:0.951564\n",
      "[25]\tvalidation_0-rmse:0.945381\n",
      "[26]\tvalidation_0-rmse:0.939371\n",
      "[27]\tvalidation_0-rmse:0.933472\n",
      "[28]\tvalidation_0-rmse:0.927688\n",
      "[29]\tvalidation_0-rmse:0.923819\n",
      "[30]\tvalidation_0-rmse:0.918091\n",
      "[31]\tvalidation_0-rmse:0.91236\n",
      "[32]\tvalidation_0-rmse:0.906802\n",
      "[33]\tvalidation_0-rmse:0.901419\n",
      "[34]\tvalidation_0-rmse:0.89781\n",
      "[35]\tvalidation_0-rmse:0.89228\n",
      "[36]\tvalidation_0-rmse:0.888747\n",
      "[37]\tvalidation_0-rmse:0.883472\n",
      "[38]\tvalidation_0-rmse:0.878418\n",
      "[39]\tvalidation_0-rmse:0.873242\n",
      "[40]\tvalidation_0-rmse:0.868268\n",
      "[41]\tvalidation_0-rmse:0.863149\n",
      "[42]\tvalidation_0-rmse:0.85815\n",
      "[43]\tvalidation_0-rmse:0.853293\n",
      "[44]\tvalidation_0-rmse:0.848391\n",
      "[45]\tvalidation_0-rmse:0.843759\n",
      "[46]\tvalidation_0-rmse:0.839147\n",
      "[47]\tvalidation_0-rmse:0.835691\n",
      "[48]\tvalidation_0-rmse:0.832312\n",
      "[49]\tvalidation_0-rmse:0.827905\n",
      "[50]\tvalidation_0-rmse:0.823469\n",
      "[51]\tvalidation_0-rmse:0.819111\n",
      "[52]\tvalidation_0-rmse:0.816371\n",
      "[53]\tvalidation_0-rmse:0.812232\n",
      "[54]\tvalidation_0-rmse:0.808088\n",
      "[55]\tvalidation_0-rmse:0.803814\n",
      "[56]\tvalidation_0-rmse:0.799623\n",
      "[57]\tvalidation_0-rmse:0.795588\n",
      "[58]\tvalidation_0-rmse:0.791587\n",
      "[59]\tvalidation_0-rmse:0.787567\n",
      "[60]\tvalidation_0-rmse:0.784501\n",
      "[61]\tvalidation_0-rmse:0.780688\n",
      "[62]\tvalidation_0-rmse:0.776834\n",
      "[63]\tvalidation_0-rmse:0.773046\n",
      "[64]\tvalidation_0-rmse:0.770393\n",
      "[65]\tvalidation_0-rmse:0.766675\n",
      "[66]\tvalidation_0-rmse:0.763125\n",
      "[67]\tvalidation_0-rmse:0.76039\n",
      "[68]\tvalidation_0-rmse:0.756895\n",
      "[69]\tvalidation_0-rmse:0.753488\n",
      "[70]\tvalidation_0-rmse:0.749996\n",
      "[71]\tvalidation_0-rmse:0.746563\n",
      "[72]\tvalidation_0-rmse:0.743286\n",
      "[73]\tvalidation_0-rmse:0.739981\n",
      "[74]\tvalidation_0-rmse:0.736765\n",
      "[75]\tvalidation_0-rmse:0.733687\n",
      "[76]\tvalidation_0-rmse:0.730501\n",
      "[77]\tvalidation_0-rmse:0.727477\n",
      "[78]\tvalidation_0-rmse:0.724643\n",
      "[79]\tvalidation_0-rmse:0.721636\n",
      "[80]\tvalidation_0-rmse:0.719405\n",
      "[81]\tvalidation_0-rmse:0.716441\n",
      "[82]\tvalidation_0-rmse:0.713533\n",
      "[83]\tvalidation_0-rmse:0.711651\n",
      "[84]\tvalidation_0-rmse:0.708828\n",
      "[85]\tvalidation_0-rmse:0.706208\n",
      "[86]\tvalidation_0-rmse:0.703467\n",
      "[87]\tvalidation_0-rmse:0.700896\n",
      "[88]\tvalidation_0-rmse:0.698466\n",
      "[89]\tvalidation_0-rmse:0.696596\n",
      "[90]\tvalidation_0-rmse:0.694072\n",
      "[91]\tvalidation_0-rmse:0.692078\n",
      "[92]\tvalidation_0-rmse:0.689565\n",
      "[93]\tvalidation_0-rmse:0.687079\n",
      "[94]\tvalidation_0-rmse:0.684655\n",
      "[95]\tvalidation_0-rmse:0.682526\n",
      "[96]\tvalidation_0-rmse:0.680221\n",
      "[97]\tvalidation_0-rmse:0.677908\n",
      "[98]\tvalidation_0-rmse:0.675883\n",
      "[99]\tvalidation_0-rmse:0.673623\n",
      "[100]\tvalidation_0-rmse:0.671285\n",
      "[101]\tvalidation_0-rmse:0.669494\n",
      "[102]\tvalidation_0-rmse:0.667288\n",
      "[103]\tvalidation_0-rmse:0.66568\n",
      "[104]\tvalidation_0-rmse:0.664274\n",
      "[105]\tvalidation_0-rmse:0.662706\n",
      "[106]\tvalidation_0-rmse:0.660683\n",
      "[107]\tvalidation_0-rmse:0.659082\n",
      "[108]\tvalidation_0-rmse:0.657073\n",
      "[109]\tvalidation_0-rmse:0.655077\n",
      "[110]\tvalidation_0-rmse:0.653081\n",
      "[111]\tvalidation_0-rmse:0.651238\n",
      "[112]\tvalidation_0-rmse:0.649308\n",
      "[113]\tvalidation_0-rmse:0.647863\n",
      "[114]\tvalidation_0-rmse:0.645987\n",
      "[115]\tvalidation_0-rmse:0.644048\n",
      "[116]\tvalidation_0-rmse:0.642246\n",
      "[117]\tvalidation_0-rmse:0.640868\n",
      "[118]\tvalidation_0-rmse:0.639121\n",
      "[119]\tvalidation_0-rmse:0.637788\n",
      "[120]\tvalidation_0-rmse:0.636806\n",
      "[121]\tvalidation_0-rmse:0.635193\n",
      "[122]\tvalidation_0-rmse:0.633904\n",
      "[123]\tvalidation_0-rmse:0.632255\n",
      "[124]\tvalidation_0-rmse:0.630617\n",
      "[125]\tvalidation_0-rmse:0.629032\n",
      "[126]\tvalidation_0-rmse:0.627463\n",
      "[127]\tvalidation_0-rmse:0.625858\n",
      "[128]\tvalidation_0-rmse:0.624367\n",
      "[129]\tvalidation_0-rmse:0.622921\n",
      "[130]\tvalidation_0-rmse:0.621598\n",
      "[131]\tvalidation_0-rmse:0.620093\n",
      "[132]\tvalidation_0-rmse:0.618638\n",
      "[133]\tvalidation_0-rmse:0.617308\n",
      "[134]\tvalidation_0-rmse:0.615885\n",
      "[135]\tvalidation_0-rmse:0.614558\n",
      "[136]\tvalidation_0-rmse:0.61312\n",
      "[137]\tvalidation_0-rmse:0.612373\n",
      "[138]\tvalidation_0-rmse:0.610962\n",
      "[139]\tvalidation_0-rmse:0.609706\n",
      "[140]\tvalidation_0-rmse:0.608433\n",
      "[141]\tvalidation_0-rmse:0.607146\n",
      "[142]\tvalidation_0-rmse:0.605989\n",
      "[143]\tvalidation_0-rmse:0.604817\n",
      "[144]\tvalidation_0-rmse:0.603627\n",
      "[145]\tvalidation_0-rmse:0.602451\n",
      "[146]\tvalidation_0-rmse:0.601263\n",
      "[147]\tvalidation_0-rmse:0.600167\n",
      "[148]\tvalidation_0-rmse:0.599079\n",
      "[149]\tvalidation_0-rmse:0.597974\n",
      "[150]\tvalidation_0-rmse:0.596875\n",
      "[151]\tvalidation_0-rmse:0.595803\n",
      "[152]\tvalidation_0-rmse:0.594745\n",
      "[153]\tvalidation_0-rmse:0.593892\n",
      "[154]\tvalidation_0-rmse:0.592869\n",
      "[155]\tvalidation_0-rmse:0.591901\n",
      "[156]\tvalidation_0-rmse:0.590877\n",
      "[157]\tvalidation_0-rmse:0.590031\n",
      "[158]\tvalidation_0-rmse:0.58909\n",
      "[159]\tvalidation_0-rmse:0.588148\n",
      "[160]\tvalidation_0-rmse:0.587424\n",
      "[161]\tvalidation_0-rmse:0.586457\n",
      "[162]\tvalidation_0-rmse:0.585511\n",
      "[163]\tvalidation_0-rmse:0.584753\n",
      "[164]\tvalidation_0-rmse:0.583876\n",
      "[165]\tvalidation_0-rmse:0.583149\n",
      "[166]\tvalidation_0-rmse:0.582312\n",
      "[167]\tvalidation_0-rmse:0.581571\n",
      "[168]\tvalidation_0-rmse:0.580677\n",
      "[169]\tvalidation_0-rmse:0.579934\n",
      "[170]\tvalidation_0-rmse:0.579084\n",
      "[171]\tvalidation_0-rmse:0.578381\n",
      "[172]\tvalidation_0-rmse:0.577658\n",
      "[173]\tvalidation_0-rmse:0.576908\n",
      "[174]\tvalidation_0-rmse:0.576106\n",
      "[175]\tvalidation_0-rmse:0.575394\n",
      "[176]\tvalidation_0-rmse:0.574926\n",
      "[177]\tvalidation_0-rmse:0.57427\n",
      "[178]\tvalidation_0-rmse:0.573544\n",
      "[179]\tvalidation_0-rmse:0.572874\n",
      "[180]\tvalidation_0-rmse:0.572204\n",
      "[181]\tvalidation_0-rmse:0.571503\n",
      "[182]\tvalidation_0-rmse:0.570862\n",
      "[183]\tvalidation_0-rmse:0.570243\n",
      "[184]\tvalidation_0-rmse:0.569544\n",
      "[185]\tvalidation_0-rmse:0.568775\n",
      "[186]\tvalidation_0-rmse:0.568134\n",
      "[187]\tvalidation_0-rmse:0.567489\n",
      "[188]\tvalidation_0-rmse:0.56694\n",
      "[189]\tvalidation_0-rmse:0.566275\n",
      "[190]\tvalidation_0-rmse:0.565577\n",
      "[191]\tvalidation_0-rmse:0.565044\n",
      "[192]\tvalidation_0-rmse:0.564603\n",
      "[193]\tvalidation_0-rmse:0.564109\n",
      "[194]\tvalidation_0-rmse:0.563627\n",
      "[195]\tvalidation_0-rmse:0.563327\n",
      "[196]\tvalidation_0-rmse:0.562824\n",
      "[197]\tvalidation_0-rmse:0.562355\n",
      "[198]\tvalidation_0-rmse:0.561932\n",
      "[199]\tvalidation_0-rmse:0.561449\n",
      "[200]\tvalidation_0-rmse:0.560843\n",
      "[201]\tvalidation_0-rmse:0.560353\n",
      "[202]\tvalidation_0-rmse:0.560129\n",
      "[203]\tvalidation_0-rmse:0.55957\n",
      "[204]\tvalidation_0-rmse:0.559076\n",
      "[205]\tvalidation_0-rmse:0.558567\n",
      "[206]\tvalidation_0-rmse:0.558074\n",
      "[207]\tvalidation_0-rmse:0.557558\n",
      "[208]\tvalidation_0-rmse:0.557106\n",
      "[209]\tvalidation_0-rmse:0.556831\n",
      "[210]\tvalidation_0-rmse:0.556435\n",
      "[211]\tvalidation_0-rmse:0.556251\n",
      "[212]\tvalidation_0-rmse:0.555807\n",
      "[213]\tvalidation_0-rmse:0.55535\n",
      "[214]\tvalidation_0-rmse:0.554821\n",
      "[215]\tvalidation_0-rmse:0.554398\n",
      "[216]\tvalidation_0-rmse:0.553924\n",
      "[217]\tvalidation_0-rmse:0.553499\n",
      "[218]\tvalidation_0-rmse:0.552956\n",
      "[219]\tvalidation_0-rmse:0.552577\n",
      "[220]\tvalidation_0-rmse:0.552187\n",
      "[221]\tvalidation_0-rmse:0.55171\n",
      "[222]\tvalidation_0-rmse:0.551327\n",
      "[223]\tvalidation_0-rmse:0.550997\n",
      "[224]\tvalidation_0-rmse:0.550664\n",
      "[225]\tvalidation_0-rmse:0.550246\n",
      "[226]\tvalidation_0-rmse:0.54978\n",
      "[227]\tvalidation_0-rmse:0.549421\n",
      "[228]\tvalidation_0-rmse:0.549283\n",
      "[229]\tvalidation_0-rmse:0.548846\n",
      "[230]\tvalidation_0-rmse:0.548422\n",
      "[231]\tvalidation_0-rmse:0.548111\n",
      "[232]\tvalidation_0-rmse:0.54773\n",
      "[233]\tvalidation_0-rmse:0.54736\n",
      "[234]\tvalidation_0-rmse:0.546999\n",
      "[235]\tvalidation_0-rmse:0.546811\n",
      "[236]\tvalidation_0-rmse:0.546412\n",
      "[237]\tvalidation_0-rmse:0.54609\n",
      "[238]\tvalidation_0-rmse:0.545706\n",
      "[239]\tvalidation_0-rmse:0.545484\n",
      "[240]\tvalidation_0-rmse:0.545125\n",
      "[241]\tvalidation_0-rmse:0.544819\n",
      "[242]\tvalidation_0-rmse:0.544451\n",
      "[243]\tvalidation_0-rmse:0.544265\n",
      "[244]\tvalidation_0-rmse:0.54385\n",
      "[245]\tvalidation_0-rmse:0.543501\n",
      "[246]\tvalidation_0-rmse:0.54325\n",
      "[247]\tvalidation_0-rmse:0.543051\n",
      "[248]\tvalidation_0-rmse:0.542714\n",
      "[249]\tvalidation_0-rmse:0.542391\n",
      "[250]\tvalidation_0-rmse:0.542124\n",
      "[251]\tvalidation_0-rmse:0.54174\n",
      "[252]\tvalidation_0-rmse:0.541499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[253]\tvalidation_0-rmse:0.541448\n",
      "[254]\tvalidation_0-rmse:0.541219\n",
      "[255]\tvalidation_0-rmse:0.541104\n",
      "[256]\tvalidation_0-rmse:0.540846\n",
      "[257]\tvalidation_0-rmse:0.54057\n",
      "[258]\tvalidation_0-rmse:0.540304\n",
      "[259]\tvalidation_0-rmse:0.540034\n",
      "[260]\tvalidation_0-rmse:0.539816\n",
      "[261]\tvalidation_0-rmse:0.539568\n",
      "[262]\tvalidation_0-rmse:0.539327\n",
      "[263]\tvalidation_0-rmse:0.539033\n",
      "[264]\tvalidation_0-rmse:0.538992\n",
      "[265]\tvalidation_0-rmse:0.538823\n",
      "[266]\tvalidation_0-rmse:0.538564\n",
      "[267]\tvalidation_0-rmse:0.538254\n",
      "[268]\tvalidation_0-rmse:0.538051\n",
      "[269]\tvalidation_0-rmse:0.537861\n",
      "[270]\tvalidation_0-rmse:0.537553\n",
      "[271]\tvalidation_0-rmse:0.537423\n",
      "[272]\tvalidation_0-rmse:0.537297\n",
      "[273]\tvalidation_0-rmse:0.537137\n",
      "[274]\tvalidation_0-rmse:0.536981\n",
      "[275]\tvalidation_0-rmse:0.536727\n",
      "[276]\tvalidation_0-rmse:0.5366\n",
      "[277]\tvalidation_0-rmse:0.536456\n",
      "[278]\tvalidation_0-rmse:0.536364\n",
      "[279]\tvalidation_0-rmse:0.536033\n",
      "[280]\tvalidation_0-rmse:0.535898\n",
      "[281]\tvalidation_0-rmse:0.535824\n",
      "[282]\tvalidation_0-rmse:0.535618\n",
      "[283]\tvalidation_0-rmse:0.535479\n",
      "[284]\tvalidation_0-rmse:0.53541\n",
      "[285]\tvalidation_0-rmse:0.535272\n",
      "[286]\tvalidation_0-rmse:0.535023\n",
      "[287]\tvalidation_0-rmse:0.534821\n",
      "[288]\tvalidation_0-rmse:0.534644\n",
      "[289]\tvalidation_0-rmse:0.534378\n",
      "[290]\tvalidation_0-rmse:0.534201\n",
      "[291]\tvalidation_0-rmse:0.534098\n",
      "[292]\tvalidation_0-rmse:0.533821\n",
      "[293]\tvalidation_0-rmse:0.53367\n",
      "[294]\tvalidation_0-rmse:0.533516\n",
      "[295]\tvalidation_0-rmse:0.533293\n",
      "[296]\tvalidation_0-rmse:0.532985\n",
      "[297]\tvalidation_0-rmse:0.5328\n",
      "[298]\tvalidation_0-rmse:0.532608\n",
      "[299]\tvalidation_0-rmse:0.53243\n",
      "[300]\tvalidation_0-rmse:0.53225\n",
      "[301]\tvalidation_0-rmse:0.532164\n",
      "[302]\tvalidation_0-rmse:0.53196\n",
      "[303]\tvalidation_0-rmse:0.53181\n",
      "[304]\tvalidation_0-rmse:0.531634\n",
      "[305]\tvalidation_0-rmse:0.531437\n",
      "[306]\tvalidation_0-rmse:0.531217\n",
      "[307]\tvalidation_0-rmse:0.530987\n",
      "[308]\tvalidation_0-rmse:0.530886\n",
      "[309]\tvalidation_0-rmse:0.530765\n",
      "[310]\tvalidation_0-rmse:0.530478\n",
      "[311]\tvalidation_0-rmse:0.530242\n",
      "[312]\tvalidation_0-rmse:0.530079\n",
      "[313]\tvalidation_0-rmse:0.52991\n",
      "[314]\tvalidation_0-rmse:0.529862\n",
      "[315]\tvalidation_0-rmse:0.529729\n",
      "[316]\tvalidation_0-rmse:0.529597\n",
      "[317]\tvalidation_0-rmse:0.529435\n",
      "[318]\tvalidation_0-rmse:0.529266\n",
      "[319]\tvalidation_0-rmse:0.529146\n",
      "[320]\tvalidation_0-rmse:0.529002\n",
      "[321]\tvalidation_0-rmse:0.528879\n",
      "[322]\tvalidation_0-rmse:0.528688\n",
      "[323]\tvalidation_0-rmse:0.528493\n",
      "[324]\tvalidation_0-rmse:0.528344\n",
      "[325]\tvalidation_0-rmse:0.528146\n",
      "[326]\tvalidation_0-rmse:0.527941\n",
      "[327]\tvalidation_0-rmse:0.527913\n",
      "[328]\tvalidation_0-rmse:0.52779\n",
      "[329]\tvalidation_0-rmse:0.527575\n",
      "[330]\tvalidation_0-rmse:0.527427\n",
      "[331]\tvalidation_0-rmse:0.527254\n",
      "[332]\tvalidation_0-rmse:0.527117\n",
      "[333]\tvalidation_0-rmse:0.527008\n",
      "[334]\tvalidation_0-rmse:0.526847\n",
      "[335]\tvalidation_0-rmse:0.526683\n",
      "[336]\tvalidation_0-rmse:0.526506\n",
      "[337]\tvalidation_0-rmse:0.526321\n",
      "[338]\tvalidation_0-rmse:0.526182\n",
      "[339]\tvalidation_0-rmse:0.526051\n",
      "[340]\tvalidation_0-rmse:0.525843\n",
      "[341]\tvalidation_0-rmse:0.525707\n",
      "[342]\tvalidation_0-rmse:0.525495\n",
      "[343]\tvalidation_0-rmse:0.525374\n",
      "[344]\tvalidation_0-rmse:0.52531\n",
      "[345]\tvalidation_0-rmse:0.525115\n",
      "[346]\tvalidation_0-rmse:0.524933\n",
      "[347]\tvalidation_0-rmse:0.524866\n",
      "[348]\tvalidation_0-rmse:0.524668\n",
      "[349]\tvalidation_0-rmse:0.524495\n",
      "[350]\tvalidation_0-rmse:0.52444\n",
      "[351]\tvalidation_0-rmse:0.524351\n",
      "[352]\tvalidation_0-rmse:0.524192\n",
      "[353]\tvalidation_0-rmse:0.524072\n",
      "[354]\tvalidation_0-rmse:0.523946\n",
      "[355]\tvalidation_0-rmse:0.523837\n",
      "[356]\tvalidation_0-rmse:0.523674\n",
      "[357]\tvalidation_0-rmse:0.523493\n",
      "[358]\tvalidation_0-rmse:0.523324\n",
      "[359]\tvalidation_0-rmse:0.523192\n",
      "[360]\tvalidation_0-rmse:0.523096\n",
      "[361]\tvalidation_0-rmse:0.52303\n",
      "[362]\tvalidation_0-rmse:0.522915\n",
      "[363]\tvalidation_0-rmse:0.522765\n",
      "[364]\tvalidation_0-rmse:0.522665\n",
      "[365]\tvalidation_0-rmse:0.522537\n",
      "[366]\tvalidation_0-rmse:0.522475\n",
      "[367]\tvalidation_0-rmse:0.522425\n",
      "[368]\tvalidation_0-rmse:0.522355\n",
      "[369]\tvalidation_0-rmse:0.52229\n",
      "[370]\tvalidation_0-rmse:0.522195\n",
      "[371]\tvalidation_0-rmse:0.522185\n",
      "[372]\tvalidation_0-rmse:0.522093\n",
      "[373]\tvalidation_0-rmse:0.521926\n",
      "[374]\tvalidation_0-rmse:0.521887\n",
      "[375]\tvalidation_0-rmse:0.521855\n",
      "[376]\tvalidation_0-rmse:0.521719\n",
      "[377]\tvalidation_0-rmse:0.521656\n",
      "[378]\tvalidation_0-rmse:0.521626\n",
      "[379]\tvalidation_0-rmse:0.521452\n",
      "[380]\tvalidation_0-rmse:0.521436\n",
      "[381]\tvalidation_0-rmse:0.521296\n",
      "[382]\tvalidation_0-rmse:0.521132\n",
      "[383]\tvalidation_0-rmse:0.521066\n",
      "[384]\tvalidation_0-rmse:0.521007\n",
      "[385]\tvalidation_0-rmse:0.520809\n",
      "[386]\tvalidation_0-rmse:0.520724\n",
      "[387]\tvalidation_0-rmse:0.520623\n",
      "[388]\tvalidation_0-rmse:0.520598\n",
      "[389]\tvalidation_0-rmse:0.520542\n",
      "[390]\tvalidation_0-rmse:0.520499\n",
      "[391]\tvalidation_0-rmse:0.520376\n",
      "[392]\tvalidation_0-rmse:0.520185\n",
      "[393]\tvalidation_0-rmse:0.520143\n",
      "[394]\tvalidation_0-rmse:0.520063\n",
      "[395]\tvalidation_0-rmse:0.519997\n",
      "[396]\tvalidation_0-rmse:0.519951\n",
      "[397]\tvalidation_0-rmse:0.519867\n",
      "[398]\tvalidation_0-rmse:0.51972\n",
      "[399]\tvalidation_0-rmse:0.519662\n",
      "[400]\tvalidation_0-rmse:0.519556\n",
      "[401]\tvalidation_0-rmse:0.51942\n",
      "[402]\tvalidation_0-rmse:0.519387\n",
      "[403]\tvalidation_0-rmse:0.519295\n",
      "[404]\tvalidation_0-rmse:0.519205\n",
      "[405]\tvalidation_0-rmse:0.519196\n",
      "[406]\tvalidation_0-rmse:0.519141\n",
      "[407]\tvalidation_0-rmse:0.51911\n",
      "[408]\tvalidation_0-rmse:0.519095\n",
      "[409]\tvalidation_0-rmse:0.519061\n",
      "[410]\tvalidation_0-rmse:0.51886\n",
      "[411]\tvalidation_0-rmse:0.518796\n",
      "[412]\tvalidation_0-rmse:0.518719\n",
      "[413]\tvalidation_0-rmse:0.518607\n",
      "[414]\tvalidation_0-rmse:0.518492\n",
      "[415]\tvalidation_0-rmse:0.518355\n",
      "[416]\tvalidation_0-rmse:0.518313\n",
      "[417]\tvalidation_0-rmse:0.518297\n",
      "[418]\tvalidation_0-rmse:0.518263\n",
      "[419]\tvalidation_0-rmse:0.51826\n",
      "[420]\tvalidation_0-rmse:0.518246\n",
      "[421]\tvalidation_0-rmse:0.518231\n",
      "[422]\tvalidation_0-rmse:0.518098\n",
      "[423]\tvalidation_0-rmse:0.517995\n",
      "[424]\tvalidation_0-rmse:0.517923\n",
      "[425]\tvalidation_0-rmse:0.517815\n",
      "[426]\tvalidation_0-rmse:0.517795\n",
      "[427]\tvalidation_0-rmse:0.51769\n",
      "[428]\tvalidation_0-rmse:0.517682\n",
      "[429]\tvalidation_0-rmse:0.517637\n",
      "[430]\tvalidation_0-rmse:0.517568\n",
      "[431]\tvalidation_0-rmse:0.51756\n",
      "[432]\tvalidation_0-rmse:0.517458\n",
      "[433]\tvalidation_0-rmse:0.517339\n",
      "[434]\tvalidation_0-rmse:0.517274\n",
      "[435]\tvalidation_0-rmse:0.517191\n",
      "[436]\tvalidation_0-rmse:0.51698\n",
      "[437]\tvalidation_0-rmse:0.516952\n",
      "[438]\tvalidation_0-rmse:0.516826\n",
      "[439]\tvalidation_0-rmse:0.516773\n",
      "[440]\tvalidation_0-rmse:0.516699\n",
      "[441]\tvalidation_0-rmse:0.51663\n",
      "[442]\tvalidation_0-rmse:0.516571\n",
      "[443]\tvalidation_0-rmse:0.516511\n",
      "[444]\tvalidation_0-rmse:0.516349\n",
      "[445]\tvalidation_0-rmse:0.516342\n",
      "[446]\tvalidation_0-rmse:0.516258\n",
      "[447]\tvalidation_0-rmse:0.51624\n",
      "[448]\tvalidation_0-rmse:0.516258\n",
      "[449]\tvalidation_0-rmse:0.516238\n",
      "[450]\tvalidation_0-rmse:0.516124\n",
      "[451]\tvalidation_0-rmse:0.516052\n",
      "[452]\tvalidation_0-rmse:0.515884\n",
      "[453]\tvalidation_0-rmse:0.515861\n",
      "[454]\tvalidation_0-rmse:0.515842\n",
      "[455]\tvalidation_0-rmse:0.515653\n",
      "[456]\tvalidation_0-rmse:0.515652\n",
      "[457]\tvalidation_0-rmse:0.515639\n",
      "[458]\tvalidation_0-rmse:0.515539\n",
      "[459]\tvalidation_0-rmse:0.515521\n",
      "[460]\tvalidation_0-rmse:0.515357\n",
      "[461]\tvalidation_0-rmse:0.515271\n",
      "[462]\tvalidation_0-rmse:0.515206\n",
      "[463]\tvalidation_0-rmse:0.515132\n",
      "[464]\tvalidation_0-rmse:0.515119\n",
      "[465]\tvalidation_0-rmse:0.515108\n",
      "[466]\tvalidation_0-rmse:0.514986\n",
      "[467]\tvalidation_0-rmse:0.514913\n",
      "[468]\tvalidation_0-rmse:0.514898\n",
      "[469]\tvalidation_0-rmse:0.514892\n",
      "[470]\tvalidation_0-rmse:0.514879\n",
      "[471]\tvalidation_0-rmse:0.51473\n",
      "[472]\tvalidation_0-rmse:0.514711\n",
      "[473]\tvalidation_0-rmse:0.514704\n",
      "[474]\tvalidation_0-rmse:0.514569\n",
      "[475]\tvalidation_0-rmse:0.514499\n",
      "[476]\tvalidation_0-rmse:0.514337\n",
      "[477]\tvalidation_0-rmse:0.514184\n",
      "[478]\tvalidation_0-rmse:0.514193\n",
      "[479]\tvalidation_0-rmse:0.514182\n",
      "[480]\tvalidation_0-rmse:0.514103\n",
      "[481]\tvalidation_0-rmse:0.513945\n",
      "[482]\tvalidation_0-rmse:0.513855\n",
      "[483]\tvalidation_0-rmse:0.513807\n",
      "[484]\tvalidation_0-rmse:0.513791\n",
      "[485]\tvalidation_0-rmse:0.513761\n",
      "[486]\tvalidation_0-rmse:0.513701\n",
      "[487]\tvalidation_0-rmse:0.513665\n",
      "[488]\tvalidation_0-rmse:0.51359\n",
      "[489]\tvalidation_0-rmse:0.513582\n",
      "[490]\tvalidation_0-rmse:0.513535\n",
      "[491]\tvalidation_0-rmse:0.513454\n",
      "[492]\tvalidation_0-rmse:0.513372\n",
      "[493]\tvalidation_0-rmse:0.513204\n",
      "[494]\tvalidation_0-rmse:0.513174\n",
      "[495]\tvalidation_0-rmse:0.513076\n",
      "[496]\tvalidation_0-rmse:0.513053\n",
      "[497]\tvalidation_0-rmse:0.513028\n",
      "[498]\tvalidation_0-rmse:0.513026\n",
      "[499]\tvalidation_0-rmse:0.512842\n",
      "[500]\tvalidation_0-rmse:0.512808\n",
      "[501]\tvalidation_0-rmse:0.512758\n",
      "[502]\tvalidation_0-rmse:0.512673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[503]\tvalidation_0-rmse:0.512603\n",
      "[504]\tvalidation_0-rmse:0.512517\n",
      "[505]\tvalidation_0-rmse:0.512374\n",
      "[506]\tvalidation_0-rmse:0.512266\n",
      "[507]\tvalidation_0-rmse:0.512265\n",
      "[508]\tvalidation_0-rmse:0.512099\n",
      "[509]\tvalidation_0-rmse:0.512059\n",
      "[510]\tvalidation_0-rmse:0.511999\n",
      "[511]\tvalidation_0-rmse:0.511914\n",
      "[512]\tvalidation_0-rmse:0.511766\n",
      "[513]\tvalidation_0-rmse:0.51173\n",
      "[514]\tvalidation_0-rmse:0.511722\n",
      "[515]\tvalidation_0-rmse:0.511642\n",
      "[516]\tvalidation_0-rmse:0.511532\n",
      "[517]\tvalidation_0-rmse:0.511326\n",
      "[518]\tvalidation_0-rmse:0.511331\n",
      "[519]\tvalidation_0-rmse:0.511322\n",
      "[520]\tvalidation_0-rmse:0.511319\n",
      "[521]\tvalidation_0-rmse:0.511238\n",
      "[522]\tvalidation_0-rmse:0.511161\n",
      "[523]\tvalidation_0-rmse:0.51099\n",
      "[524]\tvalidation_0-rmse:0.510938\n",
      "[525]\tvalidation_0-rmse:0.510921\n",
      "[526]\tvalidation_0-rmse:0.510808\n",
      "[527]\tvalidation_0-rmse:0.51072\n",
      "[528]\tvalidation_0-rmse:0.510648\n",
      "[529]\tvalidation_0-rmse:0.510643\n",
      "[530]\tvalidation_0-rmse:0.510566\n",
      "[531]\tvalidation_0-rmse:0.510506\n",
      "[532]\tvalidation_0-rmse:0.510451\n",
      "[533]\tvalidation_0-rmse:0.510442\n",
      "[534]\tvalidation_0-rmse:0.510375\n",
      "[535]\tvalidation_0-rmse:0.510377\n",
      "[536]\tvalidation_0-rmse:0.510317\n",
      "[537]\tvalidation_0-rmse:0.510257\n",
      "[538]\tvalidation_0-rmse:0.510195\n",
      "[539]\tvalidation_0-rmse:0.510105\n",
      "[540]\tvalidation_0-rmse:0.51004\n",
      "[541]\tvalidation_0-rmse:0.509971\n",
      "[542]\tvalidation_0-rmse:0.509933\n",
      "[543]\tvalidation_0-rmse:0.509861\n",
      "[544]\tvalidation_0-rmse:0.509848\n",
      "[545]\tvalidation_0-rmse:0.50978\n",
      "[546]\tvalidation_0-rmse:0.509729\n",
      "[547]\tvalidation_0-rmse:0.509648\n",
      "[548]\tvalidation_0-rmse:0.509592\n",
      "[549]\tvalidation_0-rmse:0.509513\n",
      "[550]\tvalidation_0-rmse:0.50944\n",
      "[551]\tvalidation_0-rmse:0.509389\n",
      "[552]\tvalidation_0-rmse:0.509272\n",
      "[553]\tvalidation_0-rmse:0.509163\n",
      "[554]\tvalidation_0-rmse:0.509078\n",
      "[555]\tvalidation_0-rmse:0.509062\n",
      "[556]\tvalidation_0-rmse:0.509046\n",
      "[557]\tvalidation_0-rmse:0.509005\n",
      "[558]\tvalidation_0-rmse:0.508976\n",
      "[559]\tvalidation_0-rmse:0.508949\n",
      "[560]\tvalidation_0-rmse:0.508878\n",
      "[561]\tvalidation_0-rmse:0.508765\n",
      "[562]\tvalidation_0-rmse:0.508732\n",
      "[563]\tvalidation_0-rmse:0.508737\n",
      "[564]\tvalidation_0-rmse:0.508665\n",
      "[565]\tvalidation_0-rmse:0.508602\n",
      "[566]\tvalidation_0-rmse:0.508607\n",
      "[567]\tvalidation_0-rmse:0.508565\n",
      "[568]\tvalidation_0-rmse:0.508432\n",
      "[569]\tvalidation_0-rmse:0.508444\n",
      "[570]\tvalidation_0-rmse:0.508397\n",
      "[571]\tvalidation_0-rmse:0.508344\n",
      "[572]\tvalidation_0-rmse:0.508294\n",
      "[573]\tvalidation_0-rmse:0.508229\n",
      "[574]\tvalidation_0-rmse:0.508112\n",
      "[575]\tvalidation_0-rmse:0.508118\n",
      "[576]\tvalidation_0-rmse:0.5081\n",
      "[577]\tvalidation_0-rmse:0.508059\n",
      "[578]\tvalidation_0-rmse:0.507987\n",
      "[579]\tvalidation_0-rmse:0.507926\n",
      "[580]\tvalidation_0-rmse:0.507925\n",
      "[581]\tvalidation_0-rmse:0.507913\n",
      "[582]\tvalidation_0-rmse:0.507925\n",
      "[583]\tvalidation_0-rmse:0.507899\n",
      "[584]\tvalidation_0-rmse:0.507855\n",
      "[585]\tvalidation_0-rmse:0.507858\n",
      "[586]\tvalidation_0-rmse:0.507834\n",
      "[587]\tvalidation_0-rmse:0.50782\n",
      "[588]\tvalidation_0-rmse:0.507825\n",
      "[589]\tvalidation_0-rmse:0.50775\n",
      "[590]\tvalidation_0-rmse:0.507641\n",
      "[591]\tvalidation_0-rmse:0.507647\n",
      "[592]\tvalidation_0-rmse:0.507529\n",
      "[593]\tvalidation_0-rmse:0.507521\n",
      "[594]\tvalidation_0-rmse:0.507512\n",
      "[595]\tvalidation_0-rmse:0.507492\n",
      "[596]\tvalidation_0-rmse:0.507398\n",
      "[597]\tvalidation_0-rmse:0.507382\n",
      "[598]\tvalidation_0-rmse:0.507281\n",
      "[599]\tvalidation_0-rmse:0.507219\n",
      "[600]\tvalidation_0-rmse:0.507157\n",
      "[601]\tvalidation_0-rmse:0.507037\n",
      "[602]\tvalidation_0-rmse:0.507006\n",
      "[603]\tvalidation_0-rmse:0.506959\n",
      "[604]\tvalidation_0-rmse:0.506913\n",
      "[605]\tvalidation_0-rmse:0.506903\n",
      "[606]\tvalidation_0-rmse:0.506903\n",
      "[607]\tvalidation_0-rmse:0.50672\n",
      "[608]\tvalidation_0-rmse:0.5067\n",
      "[609]\tvalidation_0-rmse:0.5067\n",
      "[610]\tvalidation_0-rmse:0.506667\n",
      "[611]\tvalidation_0-rmse:0.506556\n",
      "[612]\tvalidation_0-rmse:0.506501\n",
      "[613]\tvalidation_0-rmse:0.506494\n",
      "[614]\tvalidation_0-rmse:0.506491\n",
      "[615]\tvalidation_0-rmse:0.5064\n",
      "[616]\tvalidation_0-rmse:0.506404\n",
      "[617]\tvalidation_0-rmse:0.506404\n",
      "[618]\tvalidation_0-rmse:0.50638\n",
      "[619]\tvalidation_0-rmse:0.506289\n",
      "[620]\tvalidation_0-rmse:0.50622\n",
      "[621]\tvalidation_0-rmse:0.506139\n",
      "[622]\tvalidation_0-rmse:0.506054\n",
      "[623]\tvalidation_0-rmse:0.506048\n",
      "[624]\tvalidation_0-rmse:0.506049\n",
      "[625]\tvalidation_0-rmse:0.505945\n",
      "[626]\tvalidation_0-rmse:0.505915\n",
      "[627]\tvalidation_0-rmse:0.505878\n",
      "[628]\tvalidation_0-rmse:0.50587\n",
      "[629]\tvalidation_0-rmse:0.505838\n",
      "[630]\tvalidation_0-rmse:0.505831\n",
      "[631]\tvalidation_0-rmse:0.505748\n",
      "[632]\tvalidation_0-rmse:0.505683\n",
      "[633]\tvalidation_0-rmse:0.505644\n",
      "[634]\tvalidation_0-rmse:0.505587\n",
      "[635]\tvalidation_0-rmse:0.505578\n",
      "[636]\tvalidation_0-rmse:0.505573\n",
      "[637]\tvalidation_0-rmse:0.505504\n",
      "[638]\tvalidation_0-rmse:0.505493\n",
      "[639]\tvalidation_0-rmse:0.505479\n",
      "[640]\tvalidation_0-rmse:0.505398\n",
      "[641]\tvalidation_0-rmse:0.505352\n",
      "[642]\tvalidation_0-rmse:0.505341\n",
      "[643]\tvalidation_0-rmse:0.505308\n",
      "[644]\tvalidation_0-rmse:0.505283\n",
      "[645]\tvalidation_0-rmse:0.505279\n",
      "[646]\tvalidation_0-rmse:0.505268\n",
      "[647]\tvalidation_0-rmse:0.505207\n",
      "[648]\tvalidation_0-rmse:0.505215\n",
      "[649]\tvalidation_0-rmse:0.505206\n",
      "[650]\tvalidation_0-rmse:0.505186\n",
      "[651]\tvalidation_0-rmse:0.505182\n",
      "[652]\tvalidation_0-rmse:0.505177\n",
      "[653]\tvalidation_0-rmse:0.505171\n",
      "[654]\tvalidation_0-rmse:0.505141\n",
      "[655]\tvalidation_0-rmse:0.505135\n",
      "[656]\tvalidation_0-rmse:0.505034\n",
      "[657]\tvalidation_0-rmse:0.505025\n",
      "[658]\tvalidation_0-rmse:0.504968\n",
      "[659]\tvalidation_0-rmse:0.504953\n",
      "[660]\tvalidation_0-rmse:0.504947\n",
      "[661]\tvalidation_0-rmse:0.504938\n",
      "[662]\tvalidation_0-rmse:0.504916\n",
      "[663]\tvalidation_0-rmse:0.504905\n",
      "[664]\tvalidation_0-rmse:0.504823\n",
      "[665]\tvalidation_0-rmse:0.504788\n",
      "[666]\tvalidation_0-rmse:0.504714\n",
      "[667]\tvalidation_0-rmse:0.504669\n",
      "[668]\tvalidation_0-rmse:0.504671\n",
      "[669]\tvalidation_0-rmse:0.504664\n",
      "[670]\tvalidation_0-rmse:0.504631\n",
      "[671]\tvalidation_0-rmse:0.504602\n",
      "[672]\tvalidation_0-rmse:0.504581\n",
      "[673]\tvalidation_0-rmse:0.504566\n",
      "[674]\tvalidation_0-rmse:0.504485\n",
      "[675]\tvalidation_0-rmse:0.504484\n",
      "[676]\tvalidation_0-rmse:0.504474\n",
      "[677]\tvalidation_0-rmse:0.504453\n",
      "[678]\tvalidation_0-rmse:0.504467\n",
      "[679]\tvalidation_0-rmse:0.504429\n",
      "[680]\tvalidation_0-rmse:0.504379\n",
      "[681]\tvalidation_0-rmse:0.504364\n",
      "[682]\tvalidation_0-rmse:0.50437\n",
      "[683]\tvalidation_0-rmse:0.504367\n",
      "[684]\tvalidation_0-rmse:0.504373\n",
      "[685]\tvalidation_0-rmse:0.504369\n",
      "[686]\tvalidation_0-rmse:0.50431\n",
      "[687]\tvalidation_0-rmse:0.504297\n",
      "[688]\tvalidation_0-rmse:0.50429\n",
      "[689]\tvalidation_0-rmse:0.504302\n",
      "[690]\tvalidation_0-rmse:0.504292\n",
      "[691]\tvalidation_0-rmse:0.504285\n",
      "[692]\tvalidation_0-rmse:0.504256\n",
      "[693]\tvalidation_0-rmse:0.504237\n",
      "[694]\tvalidation_0-rmse:0.504225\n",
      "[695]\tvalidation_0-rmse:0.504211\n",
      "[696]\tvalidation_0-rmse:0.504212\n",
      "[697]\tvalidation_0-rmse:0.504208\n",
      "[698]\tvalidation_0-rmse:0.504161\n",
      "[699]\tvalidation_0-rmse:0.504156\n",
      "[700]\tvalidation_0-rmse:0.504139\n",
      "[701]\tvalidation_0-rmse:0.504089\n",
      "[702]\tvalidation_0-rmse:0.504027\n",
      "[703]\tvalidation_0-rmse:0.503973\n",
      "[704]\tvalidation_0-rmse:0.503963\n",
      "[705]\tvalidation_0-rmse:0.503952\n",
      "[706]\tvalidation_0-rmse:0.503918\n",
      "[707]\tvalidation_0-rmse:0.503891\n",
      "[708]\tvalidation_0-rmse:0.503869\n",
      "[709]\tvalidation_0-rmse:0.503869\n",
      "[710]\tvalidation_0-rmse:0.50387\n",
      "[711]\tvalidation_0-rmse:0.503876\n",
      "[712]\tvalidation_0-rmse:0.503817\n",
      "[713]\tvalidation_0-rmse:0.503814\n",
      "[714]\tvalidation_0-rmse:0.503792\n",
      "[715]\tvalidation_0-rmse:0.503736\n",
      "[716]\tvalidation_0-rmse:0.503723\n",
      "[717]\tvalidation_0-rmse:0.503711\n",
      "[718]\tvalidation_0-rmse:0.503615\n",
      "[719]\tvalidation_0-rmse:0.503596\n",
      "[720]\tvalidation_0-rmse:0.503569\n",
      "[721]\tvalidation_0-rmse:0.503554\n",
      "[722]\tvalidation_0-rmse:0.503519\n",
      "[723]\tvalidation_0-rmse:0.503503\n",
      "[724]\tvalidation_0-rmse:0.5035\n",
      "[725]\tvalidation_0-rmse:0.503477\n",
      "[726]\tvalidation_0-rmse:0.503461\n",
      "[727]\tvalidation_0-rmse:0.503426\n",
      "[728]\tvalidation_0-rmse:0.503411\n",
      "[729]\tvalidation_0-rmse:0.503331\n",
      "[730]\tvalidation_0-rmse:0.503322\n",
      "[731]\tvalidation_0-rmse:0.503324\n",
      "[732]\tvalidation_0-rmse:0.503306\n",
      "[733]\tvalidation_0-rmse:0.503281\n",
      "[734]\tvalidation_0-rmse:0.503278\n",
      "[735]\tvalidation_0-rmse:0.50327\n",
      "[736]\tvalidation_0-rmse:0.503245\n",
      "[737]\tvalidation_0-rmse:0.503247\n",
      "[738]\tvalidation_0-rmse:0.503188\n",
      "[739]\tvalidation_0-rmse:0.503185\n",
      "[740]\tvalidation_0-rmse:0.503156\n",
      "[741]\tvalidation_0-rmse:0.503148\n",
      "[742]\tvalidation_0-rmse:0.503102\n",
      "[743]\tvalidation_0-rmse:0.503101\n",
      "[744]\tvalidation_0-rmse:0.503108\n",
      "[745]\tvalidation_0-rmse:0.503124\n",
      "[746]\tvalidation_0-rmse:0.503096\n",
      "[747]\tvalidation_0-rmse:0.503087\n",
      "[748]\tvalidation_0-rmse:0.503014\n",
      "[749]\tvalidation_0-rmse:0.503004\n",
      "[750]\tvalidation_0-rmse:0.503004\n",
      "[751]\tvalidation_0-rmse:0.50297\n",
      "[752]\tvalidation_0-rmse:0.502939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[753]\tvalidation_0-rmse:0.502933\n",
      "[754]\tvalidation_0-rmse:0.502915\n",
      "[755]\tvalidation_0-rmse:0.502814\n",
      "[756]\tvalidation_0-rmse:0.502809\n",
      "[757]\tvalidation_0-rmse:0.50279\n",
      "[758]\tvalidation_0-rmse:0.50276\n",
      "[759]\tvalidation_0-rmse:0.502737\n",
      "[760]\tvalidation_0-rmse:0.502726\n",
      "[761]\tvalidation_0-rmse:0.502658\n",
      "[762]\tvalidation_0-rmse:0.502625\n",
      "[763]\tvalidation_0-rmse:0.502553\n",
      "[764]\tvalidation_0-rmse:0.502542\n",
      "[765]\tvalidation_0-rmse:0.502409\n",
      "[766]\tvalidation_0-rmse:0.50241\n",
      "[767]\tvalidation_0-rmse:0.502358\n",
      "[768]\tvalidation_0-rmse:0.502349\n",
      "[769]\tvalidation_0-rmse:0.50234\n",
      "[770]\tvalidation_0-rmse:0.50234\n",
      "[771]\tvalidation_0-rmse:0.502348\n",
      "[772]\tvalidation_0-rmse:0.502266\n",
      "[773]\tvalidation_0-rmse:0.502234\n",
      "[774]\tvalidation_0-rmse:0.502219\n",
      "[775]\tvalidation_0-rmse:0.502199\n",
      "[776]\tvalidation_0-rmse:0.50215\n",
      "[777]\tvalidation_0-rmse:0.502109\n",
      "[778]\tvalidation_0-rmse:0.50207\n",
      "[779]\tvalidation_0-rmse:0.502028\n",
      "[780]\tvalidation_0-rmse:0.502016\n",
      "[781]\tvalidation_0-rmse:0.501945\n",
      "[782]\tvalidation_0-rmse:0.501933\n",
      "[783]\tvalidation_0-rmse:0.501931\n",
      "[784]\tvalidation_0-rmse:0.501872\n",
      "[785]\tvalidation_0-rmse:0.501858\n",
      "[786]\tvalidation_0-rmse:0.501858\n",
      "[787]\tvalidation_0-rmse:0.501859\n",
      "[788]\tvalidation_0-rmse:0.50184\n",
      "[789]\tvalidation_0-rmse:0.501812\n",
      "[790]\tvalidation_0-rmse:0.501803\n",
      "[791]\tvalidation_0-rmse:0.501778\n",
      "[792]\tvalidation_0-rmse:0.501783\n",
      "[793]\tvalidation_0-rmse:0.501782\n",
      "[794]\tvalidation_0-rmse:0.501775\n",
      "[795]\tvalidation_0-rmse:0.501758\n",
      "[796]\tvalidation_0-rmse:0.501752\n",
      "[797]\tvalidation_0-rmse:0.501722\n",
      "[798]\tvalidation_0-rmse:0.50172\n",
      "[799]\tvalidation_0-rmse:0.501696\n",
      "[800]\tvalidation_0-rmse:0.501709\n",
      "[801]\tvalidation_0-rmse:0.501705\n",
      "[802]\tvalidation_0-rmse:0.501699\n",
      "[803]\tvalidation_0-rmse:0.501679\n",
      "[804]\tvalidation_0-rmse:0.501675\n",
      "[805]\tvalidation_0-rmse:0.501666\n",
      "[806]\tvalidation_0-rmse:0.501582\n",
      "[807]\tvalidation_0-rmse:0.501559\n",
      "[808]\tvalidation_0-rmse:0.501557\n",
      "[809]\tvalidation_0-rmse:0.501555\n",
      "[810]\tvalidation_0-rmse:0.501537\n",
      "[811]\tvalidation_0-rmse:0.501531\n",
      "[812]\tvalidation_0-rmse:0.501511\n",
      "[813]\tvalidation_0-rmse:0.501504\n",
      "[814]\tvalidation_0-rmse:0.501495\n",
      "[815]\tvalidation_0-rmse:0.501452\n",
      "[816]\tvalidation_0-rmse:0.501452\n",
      "[817]\tvalidation_0-rmse:0.501451\n",
      "[818]\tvalidation_0-rmse:0.501431\n",
      "[819]\tvalidation_0-rmse:0.501409\n",
      "[820]\tvalidation_0-rmse:0.501339\n",
      "[821]\tvalidation_0-rmse:0.501311\n",
      "[822]\tvalidation_0-rmse:0.501306\n",
      "[823]\tvalidation_0-rmse:0.501301\n",
      "[824]\tvalidation_0-rmse:0.501255\n",
      "[825]\tvalidation_0-rmse:0.501233\n",
      "[826]\tvalidation_0-rmse:0.501228\n",
      "[827]\tvalidation_0-rmse:0.501224\n",
      "[828]\tvalidation_0-rmse:0.501211\n",
      "[829]\tvalidation_0-rmse:0.501202\n",
      "[830]\tvalidation_0-rmse:0.501187\n",
      "[831]\tvalidation_0-rmse:0.501172\n",
      "[832]\tvalidation_0-rmse:0.501165\n",
      "[833]\tvalidation_0-rmse:0.501162\n",
      "[834]\tvalidation_0-rmse:0.501149\n",
      "[835]\tvalidation_0-rmse:0.501127\n",
      "[836]\tvalidation_0-rmse:0.501081\n",
      "[837]\tvalidation_0-rmse:0.501023\n",
      "[838]\tvalidation_0-rmse:0.501003\n",
      "[839]\tvalidation_0-rmse:0.501\n",
      "[840]\tvalidation_0-rmse:0.500996\n",
      "[841]\tvalidation_0-rmse:0.500975\n",
      "[842]\tvalidation_0-rmse:0.500974\n",
      "[843]\tvalidation_0-rmse:0.500969\n",
      "[844]\tvalidation_0-rmse:0.500973\n",
      "[845]\tvalidation_0-rmse:0.500967\n",
      "[846]\tvalidation_0-rmse:0.500927\n",
      "[847]\tvalidation_0-rmse:0.500907\n",
      "[848]\tvalidation_0-rmse:0.500904\n",
      "[849]\tvalidation_0-rmse:0.500878\n",
      "[850]\tvalidation_0-rmse:0.500866\n",
      "[851]\tvalidation_0-rmse:0.500851\n",
      "[852]\tvalidation_0-rmse:0.500838\n",
      "[853]\tvalidation_0-rmse:0.500826\n",
      "[854]\tvalidation_0-rmse:0.500828\n",
      "[855]\tvalidation_0-rmse:0.500809\n",
      "[856]\tvalidation_0-rmse:0.500725\n",
      "[857]\tvalidation_0-rmse:0.500724\n",
      "[858]\tvalidation_0-rmse:0.500704\n",
      "[859]\tvalidation_0-rmse:0.500646\n",
      "[860]\tvalidation_0-rmse:0.500631\n",
      "[861]\tvalidation_0-rmse:0.500629\n",
      "[862]\tvalidation_0-rmse:0.500626\n",
      "[863]\tvalidation_0-rmse:0.500624\n",
      "[864]\tvalidation_0-rmse:0.500614\n",
      "[865]\tvalidation_0-rmse:0.500608\n",
      "[866]\tvalidation_0-rmse:0.500606\n",
      "[867]\tvalidation_0-rmse:0.500594\n",
      "[868]\tvalidation_0-rmse:0.500573\n",
      "[869]\tvalidation_0-rmse:0.500552\n",
      "[870]\tvalidation_0-rmse:0.500525\n",
      "[871]\tvalidation_0-rmse:0.500521\n",
      "[872]\tvalidation_0-rmse:0.500522\n",
      "[873]\tvalidation_0-rmse:0.500488\n",
      "[874]\tvalidation_0-rmse:0.500504\n",
      "[875]\tvalidation_0-rmse:0.500482\n",
      "[876]\tvalidation_0-rmse:0.500476\n",
      "[877]\tvalidation_0-rmse:0.500474\n",
      "[878]\tvalidation_0-rmse:0.500475\n",
      "[879]\tvalidation_0-rmse:0.50043\n",
      "[880]\tvalidation_0-rmse:0.500424\n",
      "[881]\tvalidation_0-rmse:0.500416\n",
      "[882]\tvalidation_0-rmse:0.500381\n",
      "[883]\tvalidation_0-rmse:0.500369\n",
      "[884]\tvalidation_0-rmse:0.500359\n",
      "[885]\tvalidation_0-rmse:0.500361\n",
      "[886]\tvalidation_0-rmse:0.500342\n",
      "[887]\tvalidation_0-rmse:0.500337\n",
      "[888]\tvalidation_0-rmse:0.500306\n",
      "[889]\tvalidation_0-rmse:0.500304\n",
      "[890]\tvalidation_0-rmse:0.500307\n",
      "[891]\tvalidation_0-rmse:0.5003\n",
      "[892]\tvalidation_0-rmse:0.500292\n",
      "[893]\tvalidation_0-rmse:0.500276\n",
      "[894]\tvalidation_0-rmse:0.500267\n",
      "[895]\tvalidation_0-rmse:0.500253\n",
      "[896]\tvalidation_0-rmse:0.500185\n",
      "[897]\tvalidation_0-rmse:0.500179\n",
      "[898]\tvalidation_0-rmse:0.500171\n",
      "[899]\tvalidation_0-rmse:0.500165\n",
      "[900]\tvalidation_0-rmse:0.500162\n",
      "[901]\tvalidation_0-rmse:0.50016\n",
      "[902]\tvalidation_0-rmse:0.500156\n",
      "[903]\tvalidation_0-rmse:0.500144\n",
      "[904]\tvalidation_0-rmse:0.500129\n",
      "[905]\tvalidation_0-rmse:0.500128\n",
      "[906]\tvalidation_0-rmse:0.5001\n",
      "[907]\tvalidation_0-rmse:0.500076\n",
      "[908]\tvalidation_0-rmse:0.500055\n",
      "[909]\tvalidation_0-rmse:0.500038\n",
      "[910]\tvalidation_0-rmse:0.500005\n",
      "[911]\tvalidation_0-rmse:0.499959\n",
      "[912]\tvalidation_0-rmse:0.499966\n",
      "[913]\tvalidation_0-rmse:0.499831\n",
      "[914]\tvalidation_0-rmse:0.499815\n",
      "[915]\tvalidation_0-rmse:0.49979\n",
      "[916]\tvalidation_0-rmse:0.499778\n",
      "[917]\tvalidation_0-rmse:0.499776\n",
      "[918]\tvalidation_0-rmse:0.499768\n",
      "[919]\tvalidation_0-rmse:0.49977\n",
      "[920]\tvalidation_0-rmse:0.499717\n",
      "[921]\tvalidation_0-rmse:0.499649\n",
      "[922]\tvalidation_0-rmse:0.499617\n",
      "[923]\tvalidation_0-rmse:0.499619\n",
      "[924]\tvalidation_0-rmse:0.49955\n",
      "[925]\tvalidation_0-rmse:0.499519\n",
      "[926]\tvalidation_0-rmse:0.499506\n",
      "[927]\tvalidation_0-rmse:0.499486\n",
      "[928]\tvalidation_0-rmse:0.499482\n",
      "[929]\tvalidation_0-rmse:0.499476\n",
      "[930]\tvalidation_0-rmse:0.499476\n",
      "[931]\tvalidation_0-rmse:0.49948\n",
      "[932]\tvalidation_0-rmse:0.499469\n",
      "[933]\tvalidation_0-rmse:0.499461\n",
      "[934]\tvalidation_0-rmse:0.499429\n",
      "[935]\tvalidation_0-rmse:0.499428\n",
      "[936]\tvalidation_0-rmse:0.499409\n",
      "[937]\tvalidation_0-rmse:0.499402\n",
      "[938]\tvalidation_0-rmse:0.499399\n",
      "[939]\tvalidation_0-rmse:0.499391\n",
      "[940]\tvalidation_0-rmse:0.499363\n",
      "[941]\tvalidation_0-rmse:0.499335\n",
      "[942]\tvalidation_0-rmse:0.499331\n",
      "[943]\tvalidation_0-rmse:0.49929\n",
      "[944]\tvalidation_0-rmse:0.499264\n",
      "[945]\tvalidation_0-rmse:0.49926\n",
      "[946]\tvalidation_0-rmse:0.499257\n",
      "[947]\tvalidation_0-rmse:0.499244\n",
      "[948]\tvalidation_0-rmse:0.499241\n",
      "[949]\tvalidation_0-rmse:0.499239\n",
      "[950]\tvalidation_0-rmse:0.499233\n",
      "[951]\tvalidation_0-rmse:0.499168\n",
      "[952]\tvalidation_0-rmse:0.499159\n",
      "[953]\tvalidation_0-rmse:0.49911\n",
      "[954]\tvalidation_0-rmse:0.499019\n",
      "[955]\tvalidation_0-rmse:0.498998\n",
      "[956]\tvalidation_0-rmse:0.498989\n",
      "[957]\tvalidation_0-rmse:0.498986\n",
      "[958]\tvalidation_0-rmse:0.49896\n",
      "[959]\tvalidation_0-rmse:0.498955\n",
      "[960]\tvalidation_0-rmse:0.498944\n",
      "[961]\tvalidation_0-rmse:0.498948\n",
      "[962]\tvalidation_0-rmse:0.498841\n",
      "[963]\tvalidation_0-rmse:0.49883\n",
      "[964]\tvalidation_0-rmse:0.498826\n",
      "[965]\tvalidation_0-rmse:0.498822\n",
      "[966]\tvalidation_0-rmse:0.498833\n",
      "[967]\tvalidation_0-rmse:0.498827\n",
      "[968]\tvalidation_0-rmse:0.498798\n",
      "[969]\tvalidation_0-rmse:0.498771\n",
      "[970]\tvalidation_0-rmse:0.498755\n",
      "[971]\tvalidation_0-rmse:0.498749\n",
      "[972]\tvalidation_0-rmse:0.49874\n",
      "[973]\tvalidation_0-rmse:0.498717\n",
      "[974]\tvalidation_0-rmse:0.498614\n",
      "[975]\tvalidation_0-rmse:0.498616\n",
      "[976]\tvalidation_0-rmse:0.498616\n",
      "[977]\tvalidation_0-rmse:0.498602\n",
      "[978]\tvalidation_0-rmse:0.498597\n",
      "[979]\tvalidation_0-rmse:0.498596\n",
      "[980]\tvalidation_0-rmse:0.49855\n",
      "[981]\tvalidation_0-rmse:0.498546\n",
      "[982]\tvalidation_0-rmse:0.498537\n",
      "[983]\tvalidation_0-rmse:0.498538\n",
      "[984]\tvalidation_0-rmse:0.498503\n",
      "[985]\tvalidation_0-rmse:0.498425\n",
      "[986]\tvalidation_0-rmse:0.498431\n",
      "[987]\tvalidation_0-rmse:0.498411\n",
      "[988]\tvalidation_0-rmse:0.49841\n",
      "[989]\tvalidation_0-rmse:0.498401\n",
      "[990]\tvalidation_0-rmse:0.498388\n",
      "[991]\tvalidation_0-rmse:0.498387\n",
      "[992]\tvalidation_0-rmse:0.498365\n",
      "[993]\tvalidation_0-rmse:0.498357\n",
      "[994]\tvalidation_0-rmse:0.498321\n",
      "[995]\tvalidation_0-rmse:0.498315\n",
      "[996]\tvalidation_0-rmse:0.498311\n",
      "[997]\tvalidation_0-rmse:0.498273\n",
      "[998]\tvalidation_0-rmse:0.49824\n",
      "[999]\tvalidation_0-rmse:0.498209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.1, importance_type='gain',\n",
       "       learning_rate=0.01, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=11, missing=None, n_estimators=1000, n_jobs=1,\n",
       "       nthread=4, objective='reg:linear', random_state=0, reg_alpha=10,\n",
       "       reg_lambda=10, scale_pos_weight=0, seed=27, silent=True,\n",
       "       subsample=0.7)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(Xtrain,ytrain,eval_set=[(Xtest,ytest)],verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_val=xgb.evals_result()\n",
    "plt.plot(dict_val['validation_0']['rmse'])\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Number of estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=xgb.predict(Xtrain)\n",
    "y_pred_test=xgb.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 train :  0.8122692205855276\n",
      "r2 test :  0.7254554973033798\n"
     ]
    }
   ],
   "source": [
    "print('r2 train : ',r2_score(ytrain,y_pred_train))\n",
    "print('r2 test : ',r2_score(ytest,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train :  0.4430144893795227\n",
      "RMSE test :  0.5099430623776262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/preprocessing/data.py:180: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/preprocessing/data.py:180: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print('RMSE train : ',np.sqrt(mean_squared_error(scale(ytrain),scale(y_pred_train))))\n",
    "print('RMSE test : ',np.sqrt(mean_squared_error(scale(ytest),scale(y_pred_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    return 'rmsle',np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilleruppli/miniconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in log1p\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE train :  0.38820360763276834\n",
      "RMSLE test :  0.43816015492969207\n"
     ]
    }
   ],
   "source": [
    "print('RMSLE train : ',rmsle(ytrain,y_pred_train))\n",
    "print('RMSLE test : ',rmsle(ytest,y_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
