{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from the csv file saved from Bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_weather_data_filtered = pd.read_csv(r'C:\\Users\\Pawan Lapborisuth\\Dropbox\\Data Science Final Project\\features.csv',engine = 'python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further filtering the data to include only NYC lat/lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_weather_data_filtered=taxi_weather_data_filtered[(taxi_weather_data_filtered['pickup_latitude']>40.5) & (taxi_weather_data_filtered['pickup_latitude']<41.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use k-means to cluster lat/lang for linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.cluster.vq import kmeans2, whiten\n",
    "import matplotlib.pyplot as plt\n",
    "pickup_coordinates = taxi_weather_data_filtered[['pickup_latitude','pickup_longitude']]\n",
    "dropoff_coordinates = taxi_weather_data_filtered[['dropoff_latitude','dropoff_longitude']]\n",
    "pickup_x, pickup_y = kmeans2(whiten(pickup_coordinates), 50, iter = 20)  \n",
    "dropoff_x, dropoff_y = kmeans2(whiten(dropoff_coordinates), 50, iter = 20)  \n",
    "taxi_weather_data_filtered['pickup_cluster'] = pickup_y\n",
    "taxi_weather_data_filtered['dropoff_cluster'] = dropoff_y\n",
    "plt.scatter(pickup_coordinates.values[:,0], pickup_coordinates.values[:,1], c=pickup_y);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>travel_time</th>\n",
       "      <th>date_of_year</th>\n",
       "      <th>year</th>\n",
       "      <th>mo</th>\n",
       "      <th>...</th>\n",
       "      <th>day_binned</th>\n",
       "      <th>day_hour</th>\n",
       "      <th>time_binned</th>\n",
       "      <th>day_number</th>\n",
       "      <th>day_cosine</th>\n",
       "      <th>day_sine</th>\n",
       "      <th>time_cosine</th>\n",
       "      <th>time_sine</th>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>dropoff_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-18 03:25:25</td>\n",
       "      <td>40.731525</td>\n",
       "      <td>-73.988670</td>\n",
       "      <td>40.760036</td>\n",
       "      <td>-73.984856</td>\n",
       "      <td>626</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.532032</td>\n",
       "      <td>0.846724</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-25 17:09:52</td>\n",
       "      <td>40.713608</td>\n",
       "      <td>-74.013718</td>\n",
       "      <td>40.765598</td>\n",
       "      <td>-73.980713</td>\n",
       "      <td>1192</td>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.244048</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>0.999301</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-05 00:17:41</td>\n",
       "      <td>40.773960</td>\n",
       "      <td>-73.874435</td>\n",
       "      <td>40.766693</td>\n",
       "      <td>-73.955414</td>\n",
       "      <td>842</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01 07:44:33</td>\n",
       "      <td>40.749718</td>\n",
       "      <td>-73.991570</td>\n",
       "      <td>40.768169</td>\n",
       "      <td>-73.912483</td>\n",
       "      <td>1054</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.755952</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>-0.999301</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-29 14:34:21</td>\n",
       "      <td>40.762730</td>\n",
       "      <td>-73.974174</td>\n",
       "      <td>40.779640</td>\n",
       "      <td>-73.961823</td>\n",
       "      <td>538</td>\n",
       "      <td>2016-05-29</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>33</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      pickup_datetime  pickup_latitude  pickup_longitude  \\\n",
       "0           0  2016-01-18 03:25:25        40.731525        -73.988670   \n",
       "1           1  2016-01-25 17:09:52        40.713608        -74.013718   \n",
       "2           2  2016-01-05 00:17:41        40.773960        -73.874435   \n",
       "3           3  2016-01-01 07:44:33        40.749718        -73.991570   \n",
       "4           4  2016-05-29 14:34:21        40.762730        -73.974174   \n",
       "\n",
       "   dropoff_latitude  dropoff_longitude  travel_time date_of_year  year  mo  \\\n",
       "0         40.760036         -73.984856          626   2016-01-18  2016   1   \n",
       "1         40.765598         -73.980713         1192   2016-01-25  2016   1   \n",
       "2         40.766693         -73.955414          842   2016-01-05  2016   1   \n",
       "3         40.768169         -73.912483         1054   2016-01-01  2016   1   \n",
       "4         40.779640         -73.961823          538   2016-05-29  2016   5   \n",
       "\n",
       "        ...         day_binned  day_hour  time_binned  day_number  day_cosine  \\\n",
       "0       ...           0.142857       3.0     0.125000    0.160714    0.532032   \n",
       "1       ...           0.142857      17.0     0.708333    0.244048    0.037391   \n",
       "2       ...           0.285714       0.0     0.000000    0.285714   -0.222521   \n",
       "3       ...           0.714286       7.0     0.291667    0.755952    0.037391   \n",
       "4       ...           0.000000      14.0     0.583333    0.083333    0.866025   \n",
       "\n",
       "   day_sine  time_cosine  time_sine  pickup_cluster  dropoff_cluster  \n",
       "0  0.846724     0.707107   0.707107               8               34  \n",
       "1  0.999301    -0.258819  -0.965926               3                7  \n",
       "2  0.974928     1.000000   0.000000              43               25  \n",
       "3 -0.999301    -0.258819   0.965926              38                4  \n",
       "4  0.500000    -0.866025  -0.500000              33               46  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_weather_data_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score for training data: 0.5825\n",
      "R^2 score for testing data: 0.5814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Select the features to be included in the model\n",
    "X = taxi_weather_data_filtered[['distance_in_km','pickup_cluster','dropoff_cluster','day_sine','day_cosine','time_sine','time_cosine','temp','prcp','sndp','wdsp','weekday']]\n",
    "y = taxi_weather_data_filtered[['travel_time']]\n",
    "\n",
    "# Split data into the training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Create linear regression object\n",
    "regr = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# Make predictions using the training set\n",
    "y_pred_train = regr.predict(X_train)\n",
    "\n",
    "# Compute R^2 scores for the training and testing sets\n",
    "print('R^2 score for training data: %.4f' % r2_score(y_train, y_pred_train))\n",
    "print('R^2 score for testing data: %.4f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DataConversionWarning: Data with input dtype int32, float64 were all converted to float64 by the scale function.\n",
      "  del sys.path[0]\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DataConversionWarning: Data with input dtype int32, float64 were all converted to float64 by the scale function.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
      "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False),\n",
      "       fit_params=None, iid='warn', n_jobs=None,\n",
      "       param_grid={'alpha': array([1.00000e-04, 1.00080e-03, ..., 8.99099e-01, 9.00000e-01])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "0.5867717989235653\n",
      "0.001000800800800801\n",
      "R^2 score for training data: 0.5868\n",
      "R^2 score for testing data: 0.5875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Select the features to be included in the model\n",
    "X = taxi_weather_data_filtered.head(1000000)[['distance_in_km','pickup_cluster','dropoff_cluster','day_sine','day_cosine','time_sine','time_cosine','temp','prcp','sndp','wdsp','weekday']]\n",
    "y = taxi_weather_data_filtered.head(1000000)[['travel_time']]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    \n",
    "# Scale data\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "y_train_scaled = y_train - np.mean(y_train) \n",
    "X_test_scaled = preprocessing.scale(X_test)\n",
    "y_test_scaled = y_test - np.mean(y_test)\n",
    "\n",
    "# Use GridSearchCV to find alpha\n",
    "alphas = np.linspace(0.0001,0.9,1000)\n",
    "model = Lasso()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas), cv=3)\n",
    "grid.fit(X_train_scaled, y_train_scaled)\n",
    "print(grid)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)\n",
    "\n",
    "# Set up Lasso regression\n",
    "lassoreg = Lasso(alpha=grid.best_estimator_.alpha,normalize=False, max_iter=1e5)\n",
    "\n",
    "# Perform Lasso regression\n",
    "lassoreg.fit(X_train_scaled,y_train_scaled)\n",
    "\n",
    "# Make predictions using the training set\n",
    "y_pred_train = lassoreg.predict(X_train_scaled)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = lassoreg.predict(X_test_scaled)\n",
    "\n",
    "# Print R^2 scores\n",
    "print('R^2 score for training data: %.4f' % r2_score(y_train_scaled, y_pred_train))\n",
    "print('R^2 score for testing data: %.4f' % r2_score(y_test_scaled, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DataConversionWarning: Data with input dtype int32, float64 were all converted to float64 by the scale function.\n",
      "  del sys.path[0]\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DataConversionWarning: Data with input dtype int32, float64 were all converted to float64 by the scale function.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
      "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
      "       fit_params=None, iid='warn', n_jobs=None,\n",
      "       param_grid={'alpha': array([1.00000e-04, 1.00080e-03, ..., 8.99099e-01, 9.00000e-01])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "0.5867717989632822\n",
      "0.9\n",
      "R^2 score for training data: 0.5868\n",
      "R^2 score for testing data: 0.5875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Select the features to be included in the model\n",
    "X = taxi_weather_data_filtered.head(1000000)[['distance_in_km','pickup_cluster','dropoff_cluster','day_sine','day_cosine','time_sine','time_cosine','temp','prcp','sndp','wdsp','weekday']]\n",
    "y = taxi_weather_data_filtered.head(1000000)[['travel_time']]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    \n",
    "# Scale data\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "y_train_scaled = y_train - np.mean(y_train) \n",
    "X_test_scaled = preprocessing.scale(X_test)\n",
    "y_test_scaled = y_test - np.mean(y_test)\n",
    "\n",
    "# Use GridSearchCV to find alpha\n",
    "alphas = np.linspace(0.0001,0.9,1000)\n",
    "model = Ridge()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas), cv=3)\n",
    "grid.fit(X_train_scaled, y_train_scaled)\n",
    "print(grid)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)\n",
    "\n",
    "\n",
    "# Set up Lasso regression\n",
    "ridgereg = Ridge(alpha=grid.best_estimator_.alpha,normalize=False, max_iter=1e5)\n",
    "\n",
    "# Perform Lasso regression\n",
    "ridgereg.fit(X_train_scaled,y_train_scaled)\n",
    "\n",
    "# Make predictions using the training set\n",
    "y_pred_train = ridgereg.predict(X_train_scaled)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = ridgereg.predict(X_test_scaled)\n",
    "\n",
    "# Print R^2 scores\n",
    "print('R^2 score for training data: %.4f' % r2_score(y_train_scaled, y_pred_train))\n",
    "print('R^2 score for testing data: %.4f' % r2_score(y_test_scaled, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build K-nearest neighbors regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
      "       estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "          weights='uniform'),\n",
      "       fit_params=None, iid='warn', n_jobs=None,\n",
      "       param_grid={'n_neighbors': [1, 2, 5, 10, 20, 50, 100]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "0.7362793499792443\n",
      "10\n",
      "R^2 score for training data: 0.7954\n",
      "R^2 score for testing data: 0.7462\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select the features to be included in the model\n",
    "X = taxi_weather_data_filtered.head(500000)[['distance_in_km','pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude','day_sine','day_cosine','time_sine','time_cosine','temp','prcp','sndp','wdsp']]\n",
    "y = taxi_weather_data_filtered.head(500000)[['travel_time']]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "y_train_scaled = y_train - np.mean(y_train) \n",
    "X_test_scaled = preprocessing.scale(X_test)\n",
    "y_test_scaled = y_test - np.mean(y_test)\n",
    "\n",
    "# Use GridSearchCV to find the best k\n",
    "k_range = [1,2,5,10,20,50,100]\n",
    "model = neighbors.KNeighborsRegressor()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(n_neighbors=k_range), cv=3)\n",
    "grid.fit(X_train_scaled, y_train_scaled)\n",
    "print(grid)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.n_neighbors)\n",
    "\n",
    "# Set up K nearest neighbor regressor\n",
    "neigh = neighbors.KNeighborsRegressor(n_neighbors=grid.best_estimator_.n_neighbors)\n",
    "\n",
    "# Perform K nearest neighbor regressor \n",
    "neigh.fit(X_train_scaled,y_train_scaled)\n",
    "               \n",
    "# Make predictions using the training set\n",
    "y_pred_train = neigh.predict(X_train_scaled)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = neigh.predict(X_test_scaled)\n",
    "\n",
    "# Print R^2 scores\n",
    "print('R^2 score for training data: %.4f' % neigh.score(X_train_scaled, y_train_scaled))\n",
    "print('R^2 score for testing data: %.4f' % neigh.score(X_test_scaled, y_test_scaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train :  0.46237454795709015\n",
      "RMSE test :  0.5206814779941533\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print('RMSE train : ',np.sqrt(mean_squared_error(preprocessing.scale(y_train_scaled),preprocessing.scale(y_pred_train))))\n",
    "print('RMSE test : ',np.sqrt(mean_squared_error(preprocessing.scale(y_test_scaled),preprocessing.scale(y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    return 'rmsle',np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE train :  ('rmsle', travel_time    0.978891\n",
      "dtype: float64)\n",
      "RMSLE test :  ('rmsle', travel_time    1.021035\n",
      "dtype: float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in log1p\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print('RMSLE train : ',rmsle(y_train_scaled,y_pred_train))\n",
    "print('RMSLE test : ',rmsle(y_test_scaled,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
