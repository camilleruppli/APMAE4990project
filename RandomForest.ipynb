{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geohash\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>travel_time</th>\n",
       "      <th>year</th>\n",
       "      <th>mo</th>\n",
       "      <th>da</th>\n",
       "      <th>temp</th>\n",
       "      <th>visib</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day_binned</th>\n",
       "      <th>day_hour</th>\n",
       "      <th>time_binned</th>\n",
       "      <th>day_number</th>\n",
       "      <th>day_cosine</th>\n",
       "      <th>day_sine</th>\n",
       "      <th>time_cosine</th>\n",
       "      <th>time_sine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.731525</td>\n",
       "      <td>-73.988670</td>\n",
       "      <td>40.760036</td>\n",
       "      <td>-73.984856</td>\n",
       "      <td>626</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>27.1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.532032</td>\n",
       "      <td>0.846724</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.713608</td>\n",
       "      <td>-74.013718</td>\n",
       "      <td>40.765598</td>\n",
       "      <td>-73.980713</td>\n",
       "      <td>1192</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>32.7</td>\n",
       "      <td>9.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.244048</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>0.999301</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.773960</td>\n",
       "      <td>-73.874435</td>\n",
       "      <td>40.766693</td>\n",
       "      <td>-73.955414</td>\n",
       "      <td>842</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>18.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.749718</td>\n",
       "      <td>-73.991570</td>\n",
       "      <td>40.768169</td>\n",
       "      <td>-73.912483</td>\n",
       "      <td>1054</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.755952</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>-0.999301</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.762730</td>\n",
       "      <td>-73.974174</td>\n",
       "      <td>40.779640</td>\n",
       "      <td>-73.961823</td>\n",
       "      <td>538</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>77.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_latitude  pickup_longitude  dropoff_latitude  dropoff_longitude  \\\n",
       "0        40.731525        -73.988670         40.760036         -73.984856   \n",
       "1        40.713608        -74.013718         40.765598         -73.980713   \n",
       "2        40.773960        -73.874435         40.766693         -73.955414   \n",
       "3        40.749718        -73.991570         40.768169         -73.912483   \n",
       "4        40.762730        -73.974174         40.779640         -73.961823   \n",
       "\n",
       "   travel_time  year  mo  da  temp  visib  ...  day_of_week  weekday  \\\n",
       "0          626  2016   1  18  27.1    8.9  ...          1.0      1.0   \n",
       "1         1192  2016   1  25  32.7    9.6  ...          1.0      1.0   \n",
       "2          842  2016   1   5  18.4   10.0  ...          2.0      1.0   \n",
       "3         1054  2016   1   1  40.4   10.0  ...          5.0      1.0   \n",
       "4          538  2016   5  29  77.9    9.0  ...          0.0      0.0   \n",
       "\n",
       "   day_binned  day_hour  time_binned  day_number  day_cosine  day_sine  \\\n",
       "0    0.142857       3.0     0.125000    0.160714    0.532032  0.846724   \n",
       "1    0.142857      17.0     0.708333    0.244048    0.037391  0.999301   \n",
       "2    0.285714       0.0     0.000000    0.285714   -0.222521  0.974928   \n",
       "3    0.714286       7.0     0.291667    0.755952    0.037391 -0.999301   \n",
       "4    0.000000      14.0     0.583333    0.083333    0.866025  0.500000   \n",
       "\n",
       "   time_cosine  time_sine  \n",
       "0     0.707107   0.707107  \n",
       "1    -0.258819  -0.965926  \n",
       "2     1.000000   0.000000  \n",
       "3    -0.258819   0.965926  \n",
       "4    -0.866025  -0.500000  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taxidata=pd.read_csv(\"/Users/diana2/Dropbox/Spring2018Classes/DataSciIndustry/FinalProject/features.csv\")\n",
    "taxidata=pd.read_csv(r'C:\\Users\\diana\\Dropbox\\Spring2018Classes\\DataSciIndustry\\FInalProject/features.csv')\n",
    "\n",
    "taxidata = taxidata.drop(taxidata.columns[0], axis=1)\n",
    "taxidata = taxidata.drop(columns=\"pickup_datetime\", axis=1)\n",
    "taxidata = taxidata.drop(columns=\"date_of_year\", axis=1)\n",
    "taxidata = taxidata.drop(columns=\"Pickup Geohash\", axis=1)\n",
    "taxidata = taxidata.drop(columns=\"Dropoff Geohash\", axis=1)\n",
    "#taxidata = taxidata.drop(columns=\"distance_in_km\", axis=1)\n",
    "#print(taxidata.shape)\n",
    "taxidata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and define training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = taxidata.drop([\"travel_time\"], axis=1) # all rows, no label\n",
    "Y = taxidata[\"travel_time\"] # all rows, label only (travel_time)\n",
    "\n",
    "#print(X.shape)\n",
    "#print(Y.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(Y_train.shape)\n",
    "#print(Y_test.shape)\n",
    "\n",
    "X_train = X_train.iloc[0:800000,:]\n",
    "X_test = X_test.iloc[0:200000,:]\n",
    "Y_train = Y_train.iloc[0:800000,]\n",
    "Y_test = Y_test.iloc[0:200000,]\n",
    "\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(Y_train.shape)\n",
    "#print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_optimize(clf, parameters, X, y, n_jobs=1, n_folds=5, score_func=None, verbose=0):\n",
    "    if score_func:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, n_jobs=n_jobs, scoring=score_func, verbose=verbose)\n",
    "    else:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, n_jobs=n_jobs, cv=n_folds, verbose=verbose)\n",
    "    gs.fit(X, y)\n",
    "    \n",
    "    best = gs.best_estimator_\n",
    "    return best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-75218.29599646099, total= 2.5min\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-73750.14269067366, total= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-75271.45250901688, total= 2.2min\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-75296.84183691352, total= 2.2min\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-74800.81302143802, total= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.7min finished\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#Easy Random Forest\n",
    "model = RandomForestRegressor(n_estimators=20, n_jobs=-1)\n",
    "parameters = {\"n_estimators\": [50],\n",
    "              \"max_features\": [\"auto\"], # [\"auto\",\"sqrt\",\"log2\"]\n",
    "              \"max_depth\": [50]}\n",
    "best = cv_optimize(model, parameters, X_train, Y_train, n_folds=5, score_func='neg_mean_squared_error', verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Results (contiguous with above code block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# based on standard predict ################\n",
      "R^2 on training data: 0.9677\n",
      "R^2 on test data:     0.7799\n"
     ]
    }
   ],
   "source": [
    "# Fit the best Random Forest and calculate R^2 values for training and test sets\n",
    "reg=best.fit(X_train, Y_train)\n",
    "training_accuracy = reg.score(X_train, Y_train)\n",
    "test_accuracy = reg.score(X_test, Y_test)\n",
    "print(\"############# based on standard predict ################\")\n",
    "print(\"R^2 on training data: %0.4f\" % (training_accuracy))\n",
    "print(\"R^2 on test data:     %0.4f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 271.080 (this is in log-space!)\n",
      "So two thirds of the records would be a factor of less than 12019595507236507853347619142754399106861268087099559972628500454717956968880272379269178288612372734763370107124513437015366059331479781683003217600665453400485548259170603623087362238465498266018295340279845098017880980945856527538256050245541836478227256881519775449088.00 away from the real value.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Root Mean Squared Error\n",
    "rmse = np.sqrt(sklearn.metrics.mean_squared_error(reg.predict(X_test),Y_test))\n",
    "print(\"RMSE = %0.3f (this is in log-space!)\" % rmse)\n",
    "print(\"So two thirds of the records would be a factor of less than %0.2f away from the real value.\" % np.power(10,rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the most important features? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('distance_in_km', 0.6050026590932752),\n",
       " ('dropoff_latitude', 0.05713707334481019),\n",
       " ('pickup_longitude', 0.05119147573082785),\n",
       " ('dropoff_longitude', 0.050264870943778364),\n",
       " ('pickup_latitude', 0.04181589581412968),\n",
       " ('time_cosine', 0.02901557315573893),\n",
       " ('day_cosine', 0.01810780488141135),\n",
       " ('day_hour', 0.015027205520294287),\n",
       " ('time_binned', 0.013373097297582476),\n",
       " ('time_sine', 0.011911472711781562),\n",
       " ('wdsp', 0.011505733551526136),\n",
       " ('da', 0.011290129830904171),\n",
       " ('day_sine', 0.010053727338569674),\n",
       " ('temp', 0.008972744883201364),\n",
       " ('day_number', 0.008932628321444487),\n",
       " ('min', 0.00814277869807623),\n",
       " ('max', 0.007175072338710713),\n",
       " ('weekday', 0.006877571036317424),\n",
       " ('mo', 0.006851733093665959),\n",
       " ('gust', 0.006768602331087682),\n",
       " ('visib', 0.00654724222868589),\n",
       " ('prcp', 0.004939605011256528),\n",
       " ('sndp', 0.0031337221967517536),\n",
       " ('day_binned', 0.0018961663160417081),\n",
       " ('day_of_week', 0.0017060990677890743),\n",
       " ('rain_drizzle', 0.0012193081699795176),\n",
       " ('fog', 0.000645785252720676),\n",
       " ('snow_ice_pellets', 0.0004942218396410498),\n",
       " ('year', 0.0),\n",
       " ('hail', 0.0),\n",
       " ('thunder', 0.0)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the most important features?\n",
    "import operator\n",
    "dict_feat_imp = dict(zip(list(X.columns.values),reg.feature_importances_))\n",
    "\n",
    "sorted_features = sorted(dict_feat_imp.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimal numer of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2, 10 estimators: 0.9555277370940122\n",
      "Testing R2, 10 estimators: 0.7587428048917149\n",
      "Training R2, 20 estimators: 0.9632315216696417\n",
      "Testing R2, 20 estimators: 0.771309808356913\n",
      "Training R2, 30 estimators: 0.9657130576996811\n",
      "Testing R2, 30 estimators: 0.7764107892238256\n",
      "Training R2, 40 estimators: 0.9669132145811213\n",
      "Testing R2, 40 estimators: 0.778926524078088\n",
      "Training R2, 50 estimators: 0.9676886073023269\n",
      "Testing R2, 50 estimators: 0.7797394521762042\n",
      "Training R2, 60 estimators: 0.9682688482967167\n",
      "Testing R2, 60 estimators: 0.7812021505401445\n",
      "Training R2, 70 estimators: 0.9685711282115411\n",
      "Testing R2, 70 estimators: 0.7812638832389911\n",
      "Training R2, 80 estimators: 0.9688139570568745\n",
      "Testing R2, 80 estimators: 0.7817944486302382\n",
      "Training R2, 90 estimators: 0.9690004760876215\n",
      "Testing R2, 90 estimators: 0.7824383423143965\n",
      "Training R2, 100 estimators: 0.9692133793596092\n",
      "Testing R2, 100 estimators: 0.7824480813498644\n",
      "Training R2, 110 estimators: 0.9693584210020774\n",
      "Testing R2, 110 estimators: 0.7830311953197633\n",
      "Training R2, 120 estimators: 0.9694486709603157\n",
      "Testing R2, 120 estimators: 0.7830121207387233\n",
      "Training R2, 130 estimators: 0.9695250409075329\n",
      "Testing R2, 130 estimators: 0.7832459742150041\n",
      "Training R2, 140 estimators: 0.9696722547533757\n",
      "Testing R2, 140 estimators: 0.7833308733740532\n",
      "Training R2, 150 estimators: 0.9697594568137102\n",
      "Testing R2, 150 estimators: 0.7834692425160947\n",
      "Training R2, 160 estimators: 0.9697568922430562\n",
      "Testing R2, 160 estimators: 0.7836861038713947\n",
      "Training R2, 170 estimators: 0.9698204242518348\n",
      "Testing R2, 170 estimators: 0.7838409550987397\n",
      "Training R2, 180 estimators: 0.9699270995850509\n",
      "Testing R2, 180 estimators: 0.7838670800377519\n",
      "Training R2, 190 estimators: 0.969912782572642\n",
      "Testing R2, 190 estimators: 0.7837695080915877\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimators = np.arange(10, 200, 10)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for n in estimators: \n",
    "    model.set_params(n_estimators=n)\n",
    "    model.fit(X_train, Y_train)\n",
    "    train_scores.append(model.score(X_train, Y_train))\n",
    "    test_scores.append(model.score(X_test, Y_test))\n",
    "    print(\"Training R2, {} estimators: {}\".format(n, model.score(X_train, Y_train)))\n",
    "    print(\"Testing R2, {} estimators: {}\".format(n, model.score(X_test, Y_test)))\n",
    "plt.title(\"Effect of n_estimators\")\n",
    "plt.xlabel(\"n_estimator\")\n",
    "plt.ylabel(\"R2 score\")\n",
    "plt.plot(estimators, train_scores, label=\"training\")\n",
    "plt.plot(estimators, test_scores, label=\"testing\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above plot, we chose to use 50 estimators, because R2 score does not significantly increase after this point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce analysis to 10 most important features and 1 million datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-79050.80442884615, total= 1.2min\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-77853.7316232121, total= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-79198.3716977557, total= 1.2min\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-79751.52305289646, total= 1.2min\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-78771.03002605702, total= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Y_test22' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-0ecbe1ddd977>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mreg2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbest2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mtraining_accuracy2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mtest_accuracy2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test22\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"############# based on standard predict ################\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"R^2 on training data: %0.4f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtraining_accuracy2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_test22' is not defined"
     ]
    }
   ],
   "source": [
    "taxidata_10features = taxidata.drop(columns=['wdsp', 'da', 'day_sine', 'temp', 'day_number', 'min', 'max', 'weekday', 'mo', 'gust', 'visib', 'prcp', 'sndp', 'day_binned', 'day_of_week', 'rain_drizzle', 'fog', 'snow_ice_pellets', 'year', 'hail', 'thunder'])\n",
    "X2 = taxidata_10features.drop([\"travel_time\"], axis=1) # all rows, no label\n",
    "Y2 = taxidata_10features[\"travel_time\"] # all rows, label only (travel_time)\n",
    "\n",
    "#print(X.shape)\n",
    "#print(Y.shape)\n",
    "\n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X2, Y2, test_size=0.2, random_state=42)\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(Y_train.shape)\n",
    "#print(Y_test.shape)\n",
    "\n",
    "X_train2 = X_train2.iloc[0:800000,:]\n",
    "X_test2 = X_test2.iloc[0:200000,:]\n",
    "Y_train2 = Y_train2.iloc[0:800000,]\n",
    "Y_test2 = Y_test2.iloc[0:200000,]\n",
    "\n",
    "#from matplotlib import pyplot as plt\n",
    "#Easy Random Forest\n",
    "model2 = RandomForestRegressor(n_estimators=20, n_jobs=-1)\n",
    "parameters2 = {\"n_estimators\": [50],\n",
    "              \"max_features\": [\"auto\"], # [\"auto\",\"sqrt\",\"log2\"]\n",
    "              \"max_depth\": [50]}\n",
    "best2 = cv_optimize(model2, parameters2, X_train2, Y_train2, n_folds=5, score_func='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Fit the best Random Forest and calculate R^2 values for training and test sets\n",
    "reg2=best2.fit(X_train2, Y_train2)\n",
    "training_accuracy2 = reg2.score(X_train2, Y_train2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# based on standard predict ################\n",
      "R^2 on training data: 0.9659\n",
      "R^2 on test data:     0.7666\n"
     ]
    }
   ],
   "source": [
    "test_accuracy2 = reg2.score(X_test2, Y_test2)\n",
    "print(\"############# based on standard predict ################\")\n",
    "print(\"R^2 on training data: %0.4f\" % (training_accuracy2))\n",
    "print(\"R^2 on test data:     %0.4f\" % (test_accuracy2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop distance_in_km (most important feature) to see what happens to R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-77969.57491322793, total= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-76620.09647597325, total= 1.2min\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-78485.54941966369, total= 1.2min\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-78537.83880137869, total= 1.2min\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-77599.88632940265, total= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# based on standard predict ################\n",
      "R^2 on training data: 0.9664\n",
      "R^2 on test data:     0.7682\n"
     ]
    }
   ],
   "source": [
    "taxidata_9features = taxidata.drop(columns=['distance_in_km','wdsp', 'da', 'day_sine', 'temp', 'day_number', 'min', 'max', 'weekday', 'mo', 'gust', 'visib', 'prcp', 'sndp', 'day_binned', 'day_of_week', 'rain_drizzle', 'fog', 'snow_ice_pellets', 'year', 'hail', 'thunder'])\n",
    "X3 = taxidata_9features.drop([\"travel_time\"], axis=1) # all rows, no label\n",
    "Y3 = taxidata_9features[\"travel_time\"] # all rows, label only (travel_time)\n",
    "\n",
    "#print(X.shape)\n",
    "#print(Y.shape)\n",
    "\n",
    "X_train3, X_test3, Y_train3, Y_test3 = train_test_split(X3, Y3, test_size=0.2, random_state=42)\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(Y_train.shape)\n",
    "#print(Y_test.shape)\n",
    "\n",
    "X_train3 = X_train3.iloc[0:800000,:]\n",
    "X_test3 = X_test3.iloc[0:200000,:]\n",
    "Y_train3 = Y_train3.iloc[0:800000,]\n",
    "Y_test3 = Y_test3.iloc[0:200000,]\n",
    "\n",
    "#from matplotlib import pyplot as plt\n",
    "#Easy Random Forest\n",
    "model3 = RandomForestRegressor(n_estimators=20, n_jobs=-1)\n",
    "parameters3 = {\"n_estimators\": [50],\n",
    "              \"max_features\": [\"auto\"], # [\"auto\",\"sqrt\",\"log2\"]\n",
    "              \"max_depth\": [50]}\n",
    "best3 = cv_optimize(model3, parameters3, X_train3, Y_train3, n_folds=5, score_func='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Fit the best Random Forest and calculate R^2 values for training and test sets\n",
    "reg3=best3.fit(X_train3, Y_train3)\n",
    "training_accuracy3 = reg3.score(X_train3, Y_train3)\n",
    "\n",
    "test_accuracy3 = reg3.score(X_test3, Y_test3)\n",
    "print(\"############# based on standard predict ################\")\n",
    "print(\"R^2 on training data: %0.4f\" % (training_accuracy3))\n",
    "print(\"R^2 on test data:     %0.4f\" % (test_accuracy3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting result, the R2 score is approximately the same without the distance_in_km feature, which was found to be the most important feature above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Random forest with full dataset (3 million datapoints) and all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-69106.08838904348, total= 8.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  8.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-69333.50161390057, total= 8.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 17.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-69709.45258552574, total= 8.0min\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-69604.59026566047, total= 8.1min\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-69197.92113248898, total= 8.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 42.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# based on standard predict ################\n",
      "R^2 on training data: 0.9702\n",
      "R^2 on test data:     0.7955\n"
     ]
    }
   ],
   "source": [
    "X_train4, X_test4, Y_train4, Y_test4 = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(Y_train.shape)\n",
    "#print(Y_test.shape)\n",
    "\n",
    "model4 = RandomForestRegressor(n_estimators=20, n_jobs=-1)\n",
    "parameters4 = {\"n_estimators\": [50],\n",
    "              \"max_features\": [\"auto\"], # [\"auto\",\"sqrt\",\"log2\"]\n",
    "              \"max_depth\": [50]}\n",
    "best4 = cv_optimize(model4, parameters4, X_train4, Y_train4, n_folds=5, score_func='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Fit the best Random Forest and calculate R^2 values for training and test sets\n",
    "reg4=best4.fit(X_train4, Y_train4)\n",
    "training_accuracy4 = reg4.score(X_train4, Y_train4)\n",
    "\n",
    "test_accuracy4 = reg4.score(X_test4, Y_test4)\n",
    "print(\"############# based on standard predict ################\")\n",
    "print(\"R^2 on training data: %0.4f\" % (training_accuracy4))\n",
    "print(\"R^2 on test data:     %0.4f\" % (test_accuracy4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 261.041 (this is in log-space!)\n",
      "RMSLE = 0.402 (this is in log-space!)\n"
     ]
    }
   ],
   "source": [
    "#Output RMSE, RMSLE, R2\n",
    "rmse = np.sqrt(sklearn.metrics.mean_squared_error(reg4.predict(X_test4),Y_test4))\n",
    "print(\"RMSE = %0.3f (this is in log-space!)\" % rmse)\n",
    "\n",
    "rmsle = np.sqrt(sklearn.metrics.mean_squared_log_error(reg4.predict(X_test4),Y_test4))\n",
    "print(\"RMSLE = %0.3f (this is in log-space!)\" % rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the input before fitting to get a reasonable RMSE/RMSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train4, X_test4, Y_train4, Y_test4 = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(Y_train.shape)\n",
    "#print(Y_test.shape)\n",
    "\n",
    "model4 = RandomForestRegressor(n_estimators=20, n_jobs=-1)\n",
    "parameters4 = {\"n_estimators\": [50],\n",
    "              \"max_features\": [\"auto\"], # [\"auto\",\"sqrt\",\"log2\"]\n",
    "              \"max_depth\": [50]}\n",
    "\n",
    "X_train4 = scale(X_train4)\n",
    "X_test4 = scale(X_test4)\n",
    "Y_train4 = scale(Y_train4)\n",
    "Y_test4 = scale(Y_test4)\n",
    "\n",
    "best4 = cv_optimize(model4, parameters4, X_train4, Y_train4, n_folds=5, score_func='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Fit the best Random Forest and calculate R^2 values for training and test sets\n",
    "reg4=best4.fit(X_train4, Y_train4)\n",
    "training_accuracy4 = reg4.score(X_train4, Y_train4)\n",
    "\n",
    "test_accuracy4 = reg4.score(X_test4, Y_test4)\n",
    "print(\"############# based on standard predict ################\")\n",
    "print(\"R^2 on training data: %0.4f\" % (training_accuracy4))\n",
    "print(\"R^2 on test data:     %0.4f\" % (test_accuracy4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = pd.read_csv(r'C:\\Users\\diana\\Dropbox\\Spring2018Classes\\DataSciIndustry\\FInalProject\\taxi_weather_data.csv')\n",
    "testing_data = testing_data.drop(testing_data.columns[0], axis=1)\n",
    "testing_data = testing_data.drop(columns=\"pickup_datetime\", axis=1)\n",
    "testing_data = testing_data.fillna(testing_data.mean())\n",
    "predictions = reg4.predict(testing_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with 9 features related to time, day, and geographical coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-305420.4657434014, total= 3.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-306713.0368688267, total= 3.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  7.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-307079.6969256474, total= 3.3min\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-307441.01531783317, total= 3.1min\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-306625.27105859807, total= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 18.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# based on standard predict ################\n",
      "R^2 on training data: 0.8635\n",
      "R^2 on test data:     0.0764\n"
     ]
    }
   ],
   "source": [
    "X5 = taxidata[[\"time_binned\", \"time_cosine\", \"time_sine\", \"day_binned\", \"day_cosine\", \"day_sine\", \"weekday\", \"pickup_latitude\", \"pickup_longitude\"]]\n",
    "Y5 = taxidata[\"travel_time\"] # all rows, label only (travel_time)\n",
    "\n",
    "X_train5, X_test5, Y_train5, Y_test5 = train_test_split(X5, Y5, test_size=0.2, random_state=42)\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(Y_train.shape)\n",
    "#print(Y_test.shape)\n",
    "\n",
    "model5 = RandomForestRegressor(n_estimators=20, n_jobs=-1)\n",
    "parameters5 = {\"n_estimators\": [50],\n",
    "              \"max_features\": [\"auto\"], # [\"auto\",\"sqrt\",\"log2\"]\n",
    "              \"max_depth\": [50]}\n",
    "best5 = cv_optimize(model5, parameters5, X_train5, Y_train5, n_folds=5, score_func='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Fit the best Random Forest and calculate R^2 values for training and test sets\n",
    "reg5=best5.fit(X_train5, Y_train5)\n",
    "training_accuracy5 = reg5.score(X_train5, Y_train5)\n",
    "\n",
    "test_accuracy5 = reg5.score(X_test5, Y_test5)\n",
    "print(\"############# based on standard predict ################\")\n",
    "print(\"R^2 on training data: %0.4f\" % (training_accuracy5))\n",
    "print(\"R^2 on test data:     %0.4f\" % (test_accuracy5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 554.418 (this is in log-space!)\n",
      "RMSE = 0.787 (this is in log-space!)\n"
     ]
    }
   ],
   "source": [
    "#Output RMSE, RMSLE, R2\n",
    "rmse = np.sqrt(sklearn.metrics.mean_squared_error(reg5.predict(X_test5),Y_test5))\n",
    "print(\"RMSE = %0.3f (this is in log-space!)\" % rmse)\n",
    "\n",
    "rmsle = np.sqrt(sklearn.metrics.mean_squared_log_error(reg5.predict(X_test5),Y_test5))\n",
    "print(\"RMSLE = %0.3f (this is in log-space!)\" % rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative approach testing: Random hyperparameter grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 20)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 200, num = 20)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following random hyperparameter grid search parameter choice, train with random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 63.4min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 88.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Random search of parameters, using five-fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "# Fit the random search model\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify best parameters from random grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 60,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 217.2289 degrees.\n",
      "Accuracy = 39.76%.\n",
      "Model Performance\n",
      "Average Error: 203.6144 degrees.\n",
      "Accuracy = 47.66%.\n",
      "Improvement of 19.89%.\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))    \n",
    "    return accuracy\n",
    "\n",
    "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X_train, Y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, Y_test)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_test, Y_test)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on results of random search, perform grid search with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [50, 70, 80, 90],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [3, 5, 7],\n",
    "    'n_estimators': [50, 100, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model, display the best hyperparameters, evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 114.9min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 278.1min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 509.5min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 585.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 202.8605 degrees.\n",
      "Accuracy = 48.17%.\n",
      "Improvement of 21.18%.\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "grid_search.best_params_\n",
    "{'bootstrap': True,\n",
    " 'max_depth': 60,\n",
    " 'max_features': 'auto',\n",
    " 'min_samples_leaf': 2,\n",
    " 'min_samples_split': 5,\n",
    " 'n_estimators': 200}\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X_test, Y_test)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the alternative method of random grid search had low performance compared to the final model chosen for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
